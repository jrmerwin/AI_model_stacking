{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "504bc66a-d6b5-4644-8bb5-51f527d9436c",
   "metadata": {},
   "source": [
    "# GPT Agent Swarm\n",
    "This notebook uses the OpenAI API to create a swarm of Assistants that will be used to create 8 classification models for a model stacking project. The data set is split into 5 folds of data, reserving the 5th fold being reserved for validation of the final model. The dataset used in this study is the Wisconsin Breast Cancer Dataset, downloaded from the UCI Data Repository. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "b38529c2-4e4a-40a5-abec-95ec767d8884",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: openai in c:\\users\\merwi\\anaconda3\\lib\\site-packages (1.3.3)\n",
      "Requirement already satisfied: anyio<4,>=3.5.0 in c:\\users\\merwi\\anaconda3\\lib\\site-packages (from openai) (3.5.0)\n",
      "Requirement already satisfied: distro<2,>=1.7.0 in c:\\users\\merwi\\anaconda3\\lib\\site-packages (from openai) (1.8.0)\n",
      "Requirement already satisfied: httpx<1,>=0.23.0 in c:\\users\\merwi\\anaconda3\\lib\\site-packages (from openai) (0.25.1)\n",
      "Requirement already satisfied: pydantic<3,>=1.9.0 in c:\\users\\merwi\\anaconda3\\lib\\site-packages (from openai) (1.10.8)\n",
      "Requirement already satisfied: tqdm>4 in c:\\users\\merwi\\anaconda3\\lib\\site-packages (from openai) (4.65.0)\n",
      "Requirement already satisfied: typing-extensions<5,>=4.5 in c:\\users\\merwi\\anaconda3\\lib\\site-packages (from openai) (4.7.1)\n",
      "Requirement already satisfied: idna>=2.8 in c:\\users\\merwi\\anaconda3\\lib\\site-packages (from anyio<4,>=3.5.0->openai) (3.4)\n",
      "Requirement already satisfied: sniffio>=1.1 in c:\\users\\merwi\\anaconda3\\lib\\site-packages (from anyio<4,>=3.5.0->openai) (1.2.0)\n",
      "Requirement already satisfied: certifi in c:\\users\\merwi\\anaconda3\\lib\\site-packages (from httpx<1,>=0.23.0->openai) (2023.7.22)\n",
      "Requirement already satisfied: httpcore in c:\\users\\merwi\\anaconda3\\lib\\site-packages (from httpx<1,>=0.23.0->openai) (1.0.2)\n",
      "Requirement already satisfied: colorama in c:\\users\\merwi\\anaconda3\\lib\\site-packages (from tqdm>4->openai) (0.4.6)\n",
      "Requirement already satisfied: h11<0.15,>=0.13 in c:\\users\\merwi\\anaconda3\\lib\\site-packages (from httpcore->httpx<1,>=0.23.0->openai) (0.14.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install openai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "e51de6e5-737d-48eb-a529-a23ab75f0920",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import openai\n",
    "import time\n",
    "import ipywidgets as widgets\n",
    "from IPython.display import display\n",
    "from sklearn.metrics import r2_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "import pandas as pd\n",
    "from io import StringIO\n",
    "import io\n",
    "import json\n",
    "\n",
    "## Define Functions\n",
    "\n",
    "def read_and_save_file(first_file_id, file_name):    \n",
    "    # its binary, so read it and then make it a file like object\n",
    "    file_data = client.files.content(first_file_id)\n",
    "    file_data_bytes = file_data.read()\n",
    "    file_like_object = io.BytesIO(file_data_bytes)\n",
    "    #now read as csv to create df\n",
    "    returned_data = pd.read_csv(file_like_object)\n",
    "    returned_data.to_csv(file_name, index=False)\n",
    "    return returned_data\n",
    "    # file = read_and_save_file(first_file_id, \"analyst_output.csv\")\n",
    "    \n",
    "def files_from_messages(messages, asst_name):\n",
    "    first_thread_message = messages.data[0]  # Accessing the first ThreadMessage\n",
    "    message_ids = first_thread_message.file_ids\n",
    "    print(message_ids)\n",
    "    # Loop through each file ID and save the file with a sequential name\n",
    "    for i, file_id in enumerate(message_ids):\n",
    "        file_name = f\"{asst_name}_output_{i+1}.csv\"  # Generate a sequential file name\n",
    "        read_and_save_file(file_id, file_name)\n",
    "        print(f'saved {file_name}')    \n",
    "        \n",
    "def spin_up(target, base_instructions, file_id):\n",
    "    # create assistant\n",
    "    my_assistant = client.beta.assistants.create(\n",
    "        instructions=base_instructions,\n",
    "        name=\"agent\",\n",
    "        tools=[{\"type\": \"code_interpreter\"}],\n",
    "        model=\"gpt-4-1106-preview\", # gpt-4\n",
    "        file_ids=file_id)\n",
    "    message_string = \"Please execute your ACTIONS on the csv file, the target field is \" + target\n",
    "    # Create a Thread\n",
    "    thread = client.beta.threads.create()\n",
    "    # Add a Message to a Thread\n",
    "    message = client.beta.threads.messages.create(\n",
    "        thread_id=thread.id,\n",
    "        role=\"user\",\n",
    "        content= message_string)\n",
    "    # Run the Assistant\n",
    "    run = client.beta.threads.runs.create(\n",
    "        thread_id=thread.id,\n",
    "        assistant_id=my_assistant.id)\n",
    "    return my_assistant, thread, run \n",
    "    print('Finished creating Assistants')\n",
    "    #assistant, thread, run = spin_up(n, base_instructions, file_id)    \n",
    "    \n",
    "def catch_response(assistant, thread, run):\n",
    "    #time.sleep(240)  \n",
    "    # Retrieve the run status\n",
    "    run_status = client.beta.threads.runs.retrieve(\n",
    "        thread_id=thread.id,\n",
    "        run_id=run.id)\n",
    "    print('Checking for response...')\n",
    "    # If run is completed, get messages\n",
    "    if run_status.status == 'completed':\n",
    "        messages = client.beta.threads.messages.list(\n",
    "            thread_id=thread.id)\n",
    "        # Loop through messages and print content based on role\n",
    "        for msg in messages.data:\n",
    "            role = msg.role\n",
    "            try:\n",
    "                content = msg.content[0].text.value\n",
    "                print(f\"{role.capitalize()}: {content}\")\n",
    "                return messages, content\n",
    "            except AttributeError:\n",
    "                # This will execute if .text does not exist\n",
    "                print(f\"{role.capitalize()}: [Non-text content, possibly an image or other file type]\")\n",
    "    else:\n",
    "        print('no response yet')\n",
    "    #messages, content = catch_response(assistant, thread, run)   \n",
    "    \n",
    "def spin_down(my_assistant_id):\n",
    "    response = client.beta.assistants.delete(my_assistant_id)\n",
    "    print(response)  \n",
    "    #spin_down(my_assistant_id)\n",
    "\n",
    "def upload_csv(file_name):\n",
    "    response = client.files.create(\n",
    "        file=open(file_name, \"rb\"),\n",
    "        purpose=\"assistants\")\n",
    "    print(response)\n",
    "    file_id = response.id\n",
    "    return file_id\n",
    "\n",
    "def delete_all_assistant_files():\n",
    "    ''' Deletes all exising files uploaded to client using API key '''\n",
    "    # generate a files object\n",
    "    files_object = client.files.list()\n",
    "    # get a list comprehension\n",
    "    file_ids = [file.id for file in files_object.data]\n",
    "    print(f'Deleting {len(file_ids)} files.')\n",
    "    #delete them all\n",
    "    for file_id in file_ids:\n",
    "        client.files.delete(file_id)\n",
    "        print(f\"Deleted file with ID: {file_id}\")\n",
    "    print('Finished deleting all files')\n",
    "\n",
    "def create_dataframes_from_messages(messages, client):\n",
    "    loop_dfs = []\n",
    "    first_thread_message = messages.data[0]  # Accessing the first ThreadMessage\n",
    "    message_ids = first_thread_message.file_ids\n",
    "    # Loop through each file ID and create a DataFrame\n",
    "    for file_id in message_ids:\n",
    "        # Read the file content\n",
    "        file_data = client.files.content(file_id)\n",
    "        file_data_bytes = file_data.read()\n",
    "        file_like_object = io.BytesIO(file_data_bytes)\n",
    "        # Create a DataFrame from the file-like object and append\n",
    "        df = pd.read_csv(file_like_object)\n",
    "        loop_dfs.append(df)\n",
    "    return loop_dfs\n",
    "\n",
    "def consolidate_response_dfs(df_list):\n",
    "    # Extract 'actual_mpg' from the first DataFrame\n",
    "    actual = df_list[0][0][0][['row_id', 'test_target']].drop_duplicates('row_id')\n",
    "    # create empty DataFrame for the predicted_mpg values\n",
    "    predicted_df = pd.DataFrame()\n",
    "    # Loop through each DataFrame in the list\n",
    "    for i, df_tuple in enumerate(df_list):\n",
    "        # Check if the tuple is not empty\n",
    "        if df_tuple:\n",
    "            df = df_tuple[0][0]\n",
    "            # Check if 'predicted_target_prob' column exists in df\n",
    "            if 'predicted_target_prob' in df.columns:\n",
    "                # Rename 'predicted_mpg' column to match which agent predicted it \n",
    "                #df = df.rename(columns={'predicted_target_prob': f'predicted_target_prob{i+1}'}) s[:n] \n",
    "                model = df_list[i][1]\n",
    "                train = df_list[i][2]\n",
    "                column_name = model[:3] + train[-5:]\n",
    "                df = df.rename(columns={'predicted_target_prob': column_name})\n",
    "                # Select only the 'row_id' and the renamed 'predicted_mpg' column\n",
    "                #df = df[['row_id', f'predicted_target_prob{i+1}']]\n",
    "                df = df[['row_id', column_name]]\n",
    "                # initialize predicted_mpg_df on the first iteration\n",
    "                if i == 0:\n",
    "                    predicted_df = df\n",
    "                else:\n",
    "                    # Join using 'row_id'\n",
    "                    predicted_df = predicted_df.merge(df, on='row_id', how='outer')\n",
    "            else:\n",
    "                print(f'Column \"predicted_target_prob\" not found in run {i}')\n",
    "        else:\n",
    "            print(f'run {i} is empty')\n",
    "    # Join the 'actual_mpg' with the predicted_mpg_df\n",
    "    consolidated_df = actual.merge(predicted_df, on='row_id', how='outer')\n",
    "    # Calculate the average of the predictions and add it as a new column\n",
    "    prediction_columns = [col for col in consolidated_df.columns if col.startswith('predicted_target_prob')]\n",
    "    consolidated_df = consolidated_df.dropna()\n",
    "    consolidated_df = consolidated_df.drop_duplicates()\n",
    "    return consolidated_df\n",
    "\n",
    "def calculate_r2(df, predicted_column):\n",
    "    # Extract the actual and predicted values\n",
    "    actual = df['actual_mpg']\n",
    "    predicted = df[predicted_column]\n",
    "    # Calculate the R² score\n",
    "    r2 = r2_score(actual, predicted)\n",
    "    return r2\n",
    "\n",
    "def get_train_test_sets(train_files, test_index):\n",
    "    ''' compile all the training folds, leave the testing fold separate '''\n",
    "    # Get the test file using the index\n",
    "    test_file = train_files[test_index]\n",
    "    test_set = pd.read_csv(test_file)\n",
    "    # Initialize empty DataFrame for the training set\n",
    "    train_set = pd.DataFrame()\n",
    "    # Loop through the files and combine them into the training set\n",
    "    for i, train_file in enumerate(train_files):\n",
    "        if i != test_index:  # Exclude the test file\n",
    "            train_data = pd.read_csv(train_file)\n",
    "            train_set = pd.concat([train_set, train_data], ignore_index=True)\n",
    "    return test_set, train_set\n",
    "\n",
    "def give_new_file(assistant, file_name):\n",
    "    # give assistant a new file\n",
    "    train_fold_id = upload_csv(file_name)\n",
    "    file_ids = [train_fold_id]\n",
    "    updated_assistant = client.beta.assistants.update(\n",
    "      assistant.id,\n",
    "      file_ids=file_ids,)\n",
    "    return updated_assistant\n",
    "\n",
    "def follow_up_message(updated_assistant, thread, follow_up_text):\n",
    "    # Create a message to append to our thread\n",
    "    message = client.beta.threads.messages.create(thread_id=thread.id, role=\"user\", content=follow_up_text)\n",
    "    # Execute run\n",
    "    run = client.beta.threads.runs.create(thread_id=thread.id, assistant_id=updated_assistant.id,)\n",
    "    return run, thread\n",
    "\n",
    "def wait_on_run(run, thread):\n",
    "    while run.status == \"queued\" or run.status == \"in_progress\":\n",
    "        run = client.beta.threads.runs.retrieve(\n",
    "            thread_id=thread.id,\n",
    "            run_id=run.id,)\n",
    "        time.sleep(0.5)\n",
    "    return run\n",
    "\n",
    "def delete_all_agents():\n",
    "    # Fetch the list of assistants\n",
    "    my_assistants = client.beta.assistants.list(order=\"desc\", limit=20)\n",
    "    asst_ids = [asst.id for asst in my_assistants.data]\n",
    "    print(f'Deleting {len(asst_ids)} assistants.')\n",
    "    # Delete each assistant\n",
    "    for asst_id in asst_ids:\n",
    "        client.beta.assistants.delete(asst_id)\n",
    "        print(f\"Deleted assistant with ID: {asst_id}\")\n",
    "    print('Finished deleting all assistants')\n",
    "    \n",
    "def calculate_performance_metrics(df, actual_col, predicted_col, threshold=0.5):\n",
    "    # Extracting actual and predicted values\n",
    "    actuals = df[actual_col]\n",
    "    predictions = df[predicted_col]\n",
    "    # Apply threshold to convert probabilities to binary labels\n",
    "    binary_predictions = [1 if x >= threshold else 0 for x in predictions]\n",
    "    # Calculating confusion matrix elements\n",
    "    TN, FP, FN, TP = confusion_matrix(actuals, binary_predictions).ravel()\n",
    "    # Calculating accuracy, recall, and precision\n",
    "    accuracy = accuracy_score(actuals, binary_predictions)\n",
    "    recall = recall_score(actuals, binary_predictions)\n",
    "    precision = precision_score(actuals, binary_predictions)\n",
    "    return [FN, FP, TN, TP, accuracy, recall, precision]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb40c4b1-bd88-4397-abeb-20cd98f32a49",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Initialize API Session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "18c2b56e-12c0-427a-add2-d5c902bd0c24",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# set key and assistant ID\n",
    "OPENAI_API_KEY = '<your api key here>'\n",
    "\n",
    "# Instantiate the OpenAI client\n",
    "client = openai.OpenAI(api_key=OPENAI_API_KEY)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "792f7b12-9455-47cc-83ba-6ebbd1e5fc8d",
   "metadata": {},
   "source": [
    "# Upload Data Set and Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "a7752273-342e-4d54-b8bc-c2afe702e8b8",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The percentage of class_1 values in the data set is 0.37258347978910367\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>row_id</th>\n",
       "      <th>diagnosis</th>\n",
       "      <th>radius_mean</th>\n",
       "      <th>texture_mean</th>\n",
       "      <th>perimeter_mean</th>\n",
       "      <th>area_mean</th>\n",
       "      <th>smoothness_mean</th>\n",
       "      <th>compactness_mean</th>\n",
       "      <th>concavity_mean</th>\n",
       "      <th>concave points_mean</th>\n",
       "      <th>...</th>\n",
       "      <th>radius_worst</th>\n",
       "      <th>texture_worst</th>\n",
       "      <th>perimeter_worst</th>\n",
       "      <th>area_worst</th>\n",
       "      <th>smoothness_worst</th>\n",
       "      <th>compactness_worst</th>\n",
       "      <th>concavity_worst</th>\n",
       "      <th>concave points_worst</th>\n",
       "      <th>symmetry_worst</th>\n",
       "      <th>fractal_dimension_worst</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>842302</td>\n",
       "      <td>1</td>\n",
       "      <td>17.99</td>\n",
       "      <td>10.38</td>\n",
       "      <td>122.80</td>\n",
       "      <td>1001.0</td>\n",
       "      <td>0.11840</td>\n",
       "      <td>0.27760</td>\n",
       "      <td>0.30010</td>\n",
       "      <td>0.14710</td>\n",
       "      <td>...</td>\n",
       "      <td>25.380</td>\n",
       "      <td>17.33</td>\n",
       "      <td>184.60</td>\n",
       "      <td>2019.0</td>\n",
       "      <td>0.16220</td>\n",
       "      <td>0.66560</td>\n",
       "      <td>0.7119</td>\n",
       "      <td>0.2654</td>\n",
       "      <td>0.4601</td>\n",
       "      <td>0.11890</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>842517</td>\n",
       "      <td>1</td>\n",
       "      <td>20.57</td>\n",
       "      <td>17.77</td>\n",
       "      <td>132.90</td>\n",
       "      <td>1326.0</td>\n",
       "      <td>0.08474</td>\n",
       "      <td>0.07864</td>\n",
       "      <td>0.08690</td>\n",
       "      <td>0.07017</td>\n",
       "      <td>...</td>\n",
       "      <td>24.990</td>\n",
       "      <td>23.41</td>\n",
       "      <td>158.80</td>\n",
       "      <td>1956.0</td>\n",
       "      <td>0.12380</td>\n",
       "      <td>0.18660</td>\n",
       "      <td>0.2416</td>\n",
       "      <td>0.1860</td>\n",
       "      <td>0.2750</td>\n",
       "      <td>0.08902</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>84300903</td>\n",
       "      <td>1</td>\n",
       "      <td>19.69</td>\n",
       "      <td>21.25</td>\n",
       "      <td>130.00</td>\n",
       "      <td>1203.0</td>\n",
       "      <td>0.10960</td>\n",
       "      <td>0.15990</td>\n",
       "      <td>0.19740</td>\n",
       "      <td>0.12790</td>\n",
       "      <td>...</td>\n",
       "      <td>23.570</td>\n",
       "      <td>25.53</td>\n",
       "      <td>152.50</td>\n",
       "      <td>1709.0</td>\n",
       "      <td>0.14440</td>\n",
       "      <td>0.42450</td>\n",
       "      <td>0.4504</td>\n",
       "      <td>0.2430</td>\n",
       "      <td>0.3613</td>\n",
       "      <td>0.08758</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>84348301</td>\n",
       "      <td>1</td>\n",
       "      <td>11.42</td>\n",
       "      <td>20.38</td>\n",
       "      <td>77.58</td>\n",
       "      <td>386.1</td>\n",
       "      <td>0.14250</td>\n",
       "      <td>0.28390</td>\n",
       "      <td>0.24140</td>\n",
       "      <td>0.10520</td>\n",
       "      <td>...</td>\n",
       "      <td>14.910</td>\n",
       "      <td>26.50</td>\n",
       "      <td>98.87</td>\n",
       "      <td>567.7</td>\n",
       "      <td>0.20980</td>\n",
       "      <td>0.86630</td>\n",
       "      <td>0.6869</td>\n",
       "      <td>0.2575</td>\n",
       "      <td>0.6638</td>\n",
       "      <td>0.17300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>84358402</td>\n",
       "      <td>1</td>\n",
       "      <td>20.29</td>\n",
       "      <td>14.34</td>\n",
       "      <td>135.10</td>\n",
       "      <td>1297.0</td>\n",
       "      <td>0.10030</td>\n",
       "      <td>0.13280</td>\n",
       "      <td>0.19800</td>\n",
       "      <td>0.10430</td>\n",
       "      <td>...</td>\n",
       "      <td>22.540</td>\n",
       "      <td>16.67</td>\n",
       "      <td>152.20</td>\n",
       "      <td>1575.0</td>\n",
       "      <td>0.13740</td>\n",
       "      <td>0.20500</td>\n",
       "      <td>0.4000</td>\n",
       "      <td>0.1625</td>\n",
       "      <td>0.2364</td>\n",
       "      <td>0.07678</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>564</th>\n",
       "      <td>926424</td>\n",
       "      <td>1</td>\n",
       "      <td>21.56</td>\n",
       "      <td>22.39</td>\n",
       "      <td>142.00</td>\n",
       "      <td>1479.0</td>\n",
       "      <td>0.11100</td>\n",
       "      <td>0.11590</td>\n",
       "      <td>0.24390</td>\n",
       "      <td>0.13890</td>\n",
       "      <td>...</td>\n",
       "      <td>25.450</td>\n",
       "      <td>26.40</td>\n",
       "      <td>166.10</td>\n",
       "      <td>2027.0</td>\n",
       "      <td>0.14100</td>\n",
       "      <td>0.21130</td>\n",
       "      <td>0.4107</td>\n",
       "      <td>0.2216</td>\n",
       "      <td>0.2060</td>\n",
       "      <td>0.07115</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>565</th>\n",
       "      <td>926682</td>\n",
       "      <td>1</td>\n",
       "      <td>20.13</td>\n",
       "      <td>28.25</td>\n",
       "      <td>131.20</td>\n",
       "      <td>1261.0</td>\n",
       "      <td>0.09780</td>\n",
       "      <td>0.10340</td>\n",
       "      <td>0.14400</td>\n",
       "      <td>0.09791</td>\n",
       "      <td>...</td>\n",
       "      <td>23.690</td>\n",
       "      <td>38.25</td>\n",
       "      <td>155.00</td>\n",
       "      <td>1731.0</td>\n",
       "      <td>0.11660</td>\n",
       "      <td>0.19220</td>\n",
       "      <td>0.3215</td>\n",
       "      <td>0.1628</td>\n",
       "      <td>0.2572</td>\n",
       "      <td>0.06637</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>566</th>\n",
       "      <td>926954</td>\n",
       "      <td>1</td>\n",
       "      <td>16.60</td>\n",
       "      <td>28.08</td>\n",
       "      <td>108.30</td>\n",
       "      <td>858.1</td>\n",
       "      <td>0.08455</td>\n",
       "      <td>0.10230</td>\n",
       "      <td>0.09251</td>\n",
       "      <td>0.05302</td>\n",
       "      <td>...</td>\n",
       "      <td>18.980</td>\n",
       "      <td>34.12</td>\n",
       "      <td>126.70</td>\n",
       "      <td>1124.0</td>\n",
       "      <td>0.11390</td>\n",
       "      <td>0.30940</td>\n",
       "      <td>0.3403</td>\n",
       "      <td>0.1418</td>\n",
       "      <td>0.2218</td>\n",
       "      <td>0.07820</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>567</th>\n",
       "      <td>927241</td>\n",
       "      <td>1</td>\n",
       "      <td>20.60</td>\n",
       "      <td>29.33</td>\n",
       "      <td>140.10</td>\n",
       "      <td>1265.0</td>\n",
       "      <td>0.11780</td>\n",
       "      <td>0.27700</td>\n",
       "      <td>0.35140</td>\n",
       "      <td>0.15200</td>\n",
       "      <td>...</td>\n",
       "      <td>25.740</td>\n",
       "      <td>39.42</td>\n",
       "      <td>184.60</td>\n",
       "      <td>1821.0</td>\n",
       "      <td>0.16500</td>\n",
       "      <td>0.86810</td>\n",
       "      <td>0.9387</td>\n",
       "      <td>0.2650</td>\n",
       "      <td>0.4087</td>\n",
       "      <td>0.12400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>568</th>\n",
       "      <td>92751</td>\n",
       "      <td>0</td>\n",
       "      <td>7.76</td>\n",
       "      <td>24.54</td>\n",
       "      <td>47.92</td>\n",
       "      <td>181.0</td>\n",
       "      <td>0.05263</td>\n",
       "      <td>0.04362</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>...</td>\n",
       "      <td>9.456</td>\n",
       "      <td>30.37</td>\n",
       "      <td>59.16</td>\n",
       "      <td>268.6</td>\n",
       "      <td>0.08996</td>\n",
       "      <td>0.06444</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.2871</td>\n",
       "      <td>0.07039</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>569 rows × 32 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       row_id  diagnosis  radius_mean  texture_mean  perimeter_mean  \\\n",
       "0      842302          1        17.99         10.38          122.80   \n",
       "1      842517          1        20.57         17.77          132.90   \n",
       "2    84300903          1        19.69         21.25          130.00   \n",
       "3    84348301          1        11.42         20.38           77.58   \n",
       "4    84358402          1        20.29         14.34          135.10   \n",
       "..        ...        ...          ...           ...             ...   \n",
       "564    926424          1        21.56         22.39          142.00   \n",
       "565    926682          1        20.13         28.25          131.20   \n",
       "566    926954          1        16.60         28.08          108.30   \n",
       "567    927241          1        20.60         29.33          140.10   \n",
       "568     92751          0         7.76         24.54           47.92   \n",
       "\n",
       "     area_mean  smoothness_mean  compactness_mean  concavity_mean  \\\n",
       "0       1001.0          0.11840           0.27760         0.30010   \n",
       "1       1326.0          0.08474           0.07864         0.08690   \n",
       "2       1203.0          0.10960           0.15990         0.19740   \n",
       "3        386.1          0.14250           0.28390         0.24140   \n",
       "4       1297.0          0.10030           0.13280         0.19800   \n",
       "..         ...              ...               ...             ...   \n",
       "564     1479.0          0.11100           0.11590         0.24390   \n",
       "565     1261.0          0.09780           0.10340         0.14400   \n",
       "566      858.1          0.08455           0.10230         0.09251   \n",
       "567     1265.0          0.11780           0.27700         0.35140   \n",
       "568      181.0          0.05263           0.04362         0.00000   \n",
       "\n",
       "     concave points_mean  ...  radius_worst  texture_worst  perimeter_worst  \\\n",
       "0                0.14710  ...        25.380          17.33           184.60   \n",
       "1                0.07017  ...        24.990          23.41           158.80   \n",
       "2                0.12790  ...        23.570          25.53           152.50   \n",
       "3                0.10520  ...        14.910          26.50            98.87   \n",
       "4                0.10430  ...        22.540          16.67           152.20   \n",
       "..                   ...  ...           ...            ...              ...   \n",
       "564              0.13890  ...        25.450          26.40           166.10   \n",
       "565              0.09791  ...        23.690          38.25           155.00   \n",
       "566              0.05302  ...        18.980          34.12           126.70   \n",
       "567              0.15200  ...        25.740          39.42           184.60   \n",
       "568              0.00000  ...         9.456          30.37            59.16   \n",
       "\n",
       "     area_worst  smoothness_worst  compactness_worst  concavity_worst  \\\n",
       "0        2019.0           0.16220            0.66560           0.7119   \n",
       "1        1956.0           0.12380            0.18660           0.2416   \n",
       "2        1709.0           0.14440            0.42450           0.4504   \n",
       "3         567.7           0.20980            0.86630           0.6869   \n",
       "4        1575.0           0.13740            0.20500           0.4000   \n",
       "..          ...               ...                ...              ...   \n",
       "564      2027.0           0.14100            0.21130           0.4107   \n",
       "565      1731.0           0.11660            0.19220           0.3215   \n",
       "566      1124.0           0.11390            0.30940           0.3403   \n",
       "567      1821.0           0.16500            0.86810           0.9387   \n",
       "568       268.6           0.08996            0.06444           0.0000   \n",
       "\n",
       "     concave points_worst  symmetry_worst  fractal_dimension_worst  \n",
       "0                  0.2654          0.4601                  0.11890  \n",
       "1                  0.1860          0.2750                  0.08902  \n",
       "2                  0.2430          0.3613                  0.08758  \n",
       "3                  0.2575          0.6638                  0.17300  \n",
       "4                  0.1625          0.2364                  0.07678  \n",
       "..                    ...             ...                      ...  \n",
       "564                0.2216          0.2060                  0.07115  \n",
       "565                0.1628          0.2572                  0.06637  \n",
       "566                0.1418          0.2218                  0.07820  \n",
       "567                0.2650          0.4087                  0.12400  \n",
       "568                0.0000          0.2871                  0.07039  \n",
       "\n",
       "[569 rows x 32 columns]"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# load in data set and make some modifications\n",
    "train_df = pd.read_csv('data.csv')\n",
    "train_df = train_df.rename(columns={'id': 'row_id'})\n",
    "train_df = train_df.drop('Unnamed: 32', axis=1)\n",
    "train_df = train_df.replace({'M': 1, 'B': 0})\n",
    "\n",
    "# check class distribution\n",
    "mean_diagnosis = train_df['diagnosis'].mean()\n",
    "print(f'The percentage of class_1 values in the data set is {mean_diagnosis}')\n",
    "\n",
    "train_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "3462f9c5-dd52-4be9-ae54-0223126759c6",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Split data into 5 sets using KFold\n",
    "from sklearn.model_selection import KFold\n",
    "import pandas as pd\n",
    "\n",
    "# Create KFold object\n",
    "K = 5\n",
    "kf = KFold(n_splits=K)\n",
    "fold_number = 1\n",
    "\n",
    "# load original dataset and make a few changes\n",
    "train_df = pd.read_csv('data.csv')\n",
    "train_df = train_df.rename(columns={'id': 'row_id'})\n",
    "train_df = train_df.drop('Unnamed: 32', axis=1)\n",
    "train_df = train_df.replace({'M': 1, 'B': 0})\n",
    "    \n",
    "for train_index, _ in kf.split(train_df):\n",
    "    # Create training set for each fold\n",
    "    train_fold = train_df.iloc[train_index]\n",
    "    # Saving this to a CSV file\n",
    "    train_fold.to_csv(f'train_fold_{fold_number}.csv', index=False)\n",
    "    # Increment the fold number\n",
    "    fold_number += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "81007d7a-1ced-484b-8318-73d34b0745d9",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>row_id</th>\n",
       "      <th>diagnosis</th>\n",
       "      <th>radius_mean</th>\n",
       "      <th>texture_mean</th>\n",
       "      <th>perimeter_mean</th>\n",
       "      <th>area_mean</th>\n",
       "      <th>smoothness_mean</th>\n",
       "      <th>compactness_mean</th>\n",
       "      <th>concavity_mean</th>\n",
       "      <th>concave points_mean</th>\n",
       "      <th>...</th>\n",
       "      <th>radius_worst</th>\n",
       "      <th>texture_worst</th>\n",
       "      <th>perimeter_worst</th>\n",
       "      <th>area_worst</th>\n",
       "      <th>smoothness_worst</th>\n",
       "      <th>compactness_worst</th>\n",
       "      <th>concavity_worst</th>\n",
       "      <th>concave points_worst</th>\n",
       "      <th>symmetry_worst</th>\n",
       "      <th>fractal_dimension_worst</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>864496</td>\n",
       "      <td>0</td>\n",
       "      <td>8.726</td>\n",
       "      <td>15.83</td>\n",
       "      <td>55.84</td>\n",
       "      <td>230.9</td>\n",
       "      <td>0.11500</td>\n",
       "      <td>0.08201</td>\n",
       "      <td>0.04132</td>\n",
       "      <td>0.01924</td>\n",
       "      <td>...</td>\n",
       "      <td>9.628</td>\n",
       "      <td>19.62</td>\n",
       "      <td>64.48</td>\n",
       "      <td>284.4</td>\n",
       "      <td>0.17240</td>\n",
       "      <td>0.23640</td>\n",
       "      <td>0.2456</td>\n",
       "      <td>0.10500</td>\n",
       "      <td>0.2926</td>\n",
       "      <td>0.10170</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>864685</td>\n",
       "      <td>0</td>\n",
       "      <td>11.930</td>\n",
       "      <td>21.53</td>\n",
       "      <td>76.53</td>\n",
       "      <td>438.6</td>\n",
       "      <td>0.09768</td>\n",
       "      <td>0.07849</td>\n",
       "      <td>0.03328</td>\n",
       "      <td>0.02008</td>\n",
       "      <td>...</td>\n",
       "      <td>13.670</td>\n",
       "      <td>26.15</td>\n",
       "      <td>87.54</td>\n",
       "      <td>583.0</td>\n",
       "      <td>0.15000</td>\n",
       "      <td>0.23990</td>\n",
       "      <td>0.1503</td>\n",
       "      <td>0.07247</td>\n",
       "      <td>0.2438</td>\n",
       "      <td>0.08541</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>864726</td>\n",
       "      <td>0</td>\n",
       "      <td>8.950</td>\n",
       "      <td>15.76</td>\n",
       "      <td>58.74</td>\n",
       "      <td>245.2</td>\n",
       "      <td>0.09462</td>\n",
       "      <td>0.12430</td>\n",
       "      <td>0.09263</td>\n",
       "      <td>0.02308</td>\n",
       "      <td>...</td>\n",
       "      <td>9.414</td>\n",
       "      <td>17.07</td>\n",
       "      <td>63.34</td>\n",
       "      <td>270.0</td>\n",
       "      <td>0.11790</td>\n",
       "      <td>0.18790</td>\n",
       "      <td>0.1544</td>\n",
       "      <td>0.03846</td>\n",
       "      <td>0.1652</td>\n",
       "      <td>0.07722</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>864729</td>\n",
       "      <td>1</td>\n",
       "      <td>14.870</td>\n",
       "      <td>16.67</td>\n",
       "      <td>98.64</td>\n",
       "      <td>682.5</td>\n",
       "      <td>0.11620</td>\n",
       "      <td>0.16490</td>\n",
       "      <td>0.16900</td>\n",
       "      <td>0.08923</td>\n",
       "      <td>...</td>\n",
       "      <td>18.810</td>\n",
       "      <td>27.37</td>\n",
       "      <td>127.10</td>\n",
       "      <td>1095.0</td>\n",
       "      <td>0.18780</td>\n",
       "      <td>0.44800</td>\n",
       "      <td>0.4704</td>\n",
       "      <td>0.20270</td>\n",
       "      <td>0.3585</td>\n",
       "      <td>0.10650</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>864877</td>\n",
       "      <td>1</td>\n",
       "      <td>15.780</td>\n",
       "      <td>22.91</td>\n",
       "      <td>105.70</td>\n",
       "      <td>782.6</td>\n",
       "      <td>0.11550</td>\n",
       "      <td>0.17520</td>\n",
       "      <td>0.21330</td>\n",
       "      <td>0.09479</td>\n",
       "      <td>...</td>\n",
       "      <td>20.190</td>\n",
       "      <td>30.50</td>\n",
       "      <td>130.30</td>\n",
       "      <td>1272.0</td>\n",
       "      <td>0.18550</td>\n",
       "      <td>0.49250</td>\n",
       "      <td>0.7356</td>\n",
       "      <td>0.20340</td>\n",
       "      <td>0.3274</td>\n",
       "      <td>0.12520</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>450</th>\n",
       "      <td>926424</td>\n",
       "      <td>1</td>\n",
       "      <td>21.560</td>\n",
       "      <td>22.39</td>\n",
       "      <td>142.00</td>\n",
       "      <td>1479.0</td>\n",
       "      <td>0.11100</td>\n",
       "      <td>0.11590</td>\n",
       "      <td>0.24390</td>\n",
       "      <td>0.13890</td>\n",
       "      <td>...</td>\n",
       "      <td>25.450</td>\n",
       "      <td>26.40</td>\n",
       "      <td>166.10</td>\n",
       "      <td>2027.0</td>\n",
       "      <td>0.14100</td>\n",
       "      <td>0.21130</td>\n",
       "      <td>0.4107</td>\n",
       "      <td>0.22160</td>\n",
       "      <td>0.2060</td>\n",
       "      <td>0.07115</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>451</th>\n",
       "      <td>926682</td>\n",
       "      <td>1</td>\n",
       "      <td>20.130</td>\n",
       "      <td>28.25</td>\n",
       "      <td>131.20</td>\n",
       "      <td>1261.0</td>\n",
       "      <td>0.09780</td>\n",
       "      <td>0.10340</td>\n",
       "      <td>0.14400</td>\n",
       "      <td>0.09791</td>\n",
       "      <td>...</td>\n",
       "      <td>23.690</td>\n",
       "      <td>38.25</td>\n",
       "      <td>155.00</td>\n",
       "      <td>1731.0</td>\n",
       "      <td>0.11660</td>\n",
       "      <td>0.19220</td>\n",
       "      <td>0.3215</td>\n",
       "      <td>0.16280</td>\n",
       "      <td>0.2572</td>\n",
       "      <td>0.06637</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>452</th>\n",
       "      <td>926954</td>\n",
       "      <td>1</td>\n",
       "      <td>16.600</td>\n",
       "      <td>28.08</td>\n",
       "      <td>108.30</td>\n",
       "      <td>858.1</td>\n",
       "      <td>0.08455</td>\n",
       "      <td>0.10230</td>\n",
       "      <td>0.09251</td>\n",
       "      <td>0.05302</td>\n",
       "      <td>...</td>\n",
       "      <td>18.980</td>\n",
       "      <td>34.12</td>\n",
       "      <td>126.70</td>\n",
       "      <td>1124.0</td>\n",
       "      <td>0.11390</td>\n",
       "      <td>0.30940</td>\n",
       "      <td>0.3403</td>\n",
       "      <td>0.14180</td>\n",
       "      <td>0.2218</td>\n",
       "      <td>0.07820</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>453</th>\n",
       "      <td>927241</td>\n",
       "      <td>1</td>\n",
       "      <td>20.600</td>\n",
       "      <td>29.33</td>\n",
       "      <td>140.10</td>\n",
       "      <td>1265.0</td>\n",
       "      <td>0.11780</td>\n",
       "      <td>0.27700</td>\n",
       "      <td>0.35140</td>\n",
       "      <td>0.15200</td>\n",
       "      <td>...</td>\n",
       "      <td>25.740</td>\n",
       "      <td>39.42</td>\n",
       "      <td>184.60</td>\n",
       "      <td>1821.0</td>\n",
       "      <td>0.16500</td>\n",
       "      <td>0.86810</td>\n",
       "      <td>0.9387</td>\n",
       "      <td>0.26500</td>\n",
       "      <td>0.4087</td>\n",
       "      <td>0.12400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>454</th>\n",
       "      <td>92751</td>\n",
       "      <td>0</td>\n",
       "      <td>7.760</td>\n",
       "      <td>24.54</td>\n",
       "      <td>47.92</td>\n",
       "      <td>181.0</td>\n",
       "      <td>0.05263</td>\n",
       "      <td>0.04362</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>...</td>\n",
       "      <td>9.456</td>\n",
       "      <td>30.37</td>\n",
       "      <td>59.16</td>\n",
       "      <td>268.6</td>\n",
       "      <td>0.08996</td>\n",
       "      <td>0.06444</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.2871</td>\n",
       "      <td>0.07039</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>455 rows × 32 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     row_id  diagnosis  radius_mean  texture_mean  perimeter_mean  area_mean  \\\n",
       "0    864496          0        8.726         15.83           55.84      230.9   \n",
       "1    864685          0       11.930         21.53           76.53      438.6   \n",
       "2    864726          0        8.950         15.76           58.74      245.2   \n",
       "3    864729          1       14.870         16.67           98.64      682.5   \n",
       "4    864877          1       15.780         22.91          105.70      782.6   \n",
       "..      ...        ...          ...           ...             ...        ...   \n",
       "450  926424          1       21.560         22.39          142.00     1479.0   \n",
       "451  926682          1       20.130         28.25          131.20     1261.0   \n",
       "452  926954          1       16.600         28.08          108.30      858.1   \n",
       "453  927241          1       20.600         29.33          140.10     1265.0   \n",
       "454   92751          0        7.760         24.54           47.92      181.0   \n",
       "\n",
       "     smoothness_mean  compactness_mean  concavity_mean  concave points_mean  \\\n",
       "0            0.11500           0.08201         0.04132              0.01924   \n",
       "1            0.09768           0.07849         0.03328              0.02008   \n",
       "2            0.09462           0.12430         0.09263              0.02308   \n",
       "3            0.11620           0.16490         0.16900              0.08923   \n",
       "4            0.11550           0.17520         0.21330              0.09479   \n",
       "..               ...               ...             ...                  ...   \n",
       "450          0.11100           0.11590         0.24390              0.13890   \n",
       "451          0.09780           0.10340         0.14400              0.09791   \n",
       "452          0.08455           0.10230         0.09251              0.05302   \n",
       "453          0.11780           0.27700         0.35140              0.15200   \n",
       "454          0.05263           0.04362         0.00000              0.00000   \n",
       "\n",
       "     ...  radius_worst  texture_worst  perimeter_worst  area_worst  \\\n",
       "0    ...         9.628          19.62            64.48       284.4   \n",
       "1    ...        13.670          26.15            87.54       583.0   \n",
       "2    ...         9.414          17.07            63.34       270.0   \n",
       "3    ...        18.810          27.37           127.10      1095.0   \n",
       "4    ...        20.190          30.50           130.30      1272.0   \n",
       "..   ...           ...            ...              ...         ...   \n",
       "450  ...        25.450          26.40           166.10      2027.0   \n",
       "451  ...        23.690          38.25           155.00      1731.0   \n",
       "452  ...        18.980          34.12           126.70      1124.0   \n",
       "453  ...        25.740          39.42           184.60      1821.0   \n",
       "454  ...         9.456          30.37            59.16       268.6   \n",
       "\n",
       "     smoothness_worst  compactness_worst  concavity_worst  \\\n",
       "0             0.17240            0.23640           0.2456   \n",
       "1             0.15000            0.23990           0.1503   \n",
       "2             0.11790            0.18790           0.1544   \n",
       "3             0.18780            0.44800           0.4704   \n",
       "4             0.18550            0.49250           0.7356   \n",
       "..                ...                ...              ...   \n",
       "450           0.14100            0.21130           0.4107   \n",
       "451           0.11660            0.19220           0.3215   \n",
       "452           0.11390            0.30940           0.3403   \n",
       "453           0.16500            0.86810           0.9387   \n",
       "454           0.08996            0.06444           0.0000   \n",
       "\n",
       "     concave points_worst  symmetry_worst  fractal_dimension_worst  \n",
       "0                 0.10500          0.2926                  0.10170  \n",
       "1                 0.07247          0.2438                  0.08541  \n",
       "2                 0.03846          0.1652                  0.07722  \n",
       "3                 0.20270          0.3585                  0.10650  \n",
       "4                 0.20340          0.3274                  0.12520  \n",
       "..                    ...             ...                      ...  \n",
       "450               0.22160          0.2060                  0.07115  \n",
       "451               0.16280          0.2572                  0.06637  \n",
       "452               0.14180          0.2218                  0.07820  \n",
       "453               0.26500          0.4087                  0.12400  \n",
       "454               0.00000          0.2871                  0.07039  \n",
       "\n",
       "[455 rows x 32 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# read them back in\n",
    "train_fold_1 = pd.read_csv('train_fold_1.csv')\n",
    "train_fold_2 = pd.read_csv('train_fold_2.csv')\n",
    "train_fold_3 = pd.read_csv('train_fold_3.csv')\n",
    "train_fold_4 = pd.read_csv('train_fold_4.csv')\n",
    "train_fold_5 = pd.read_csv('train_fold_5.csv')\n",
    "display(train_fold_1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27c38f1c-bb4e-44a0-b2f0-2f0ad5f49495",
   "metadata": {},
   "source": [
    "# Create the Swarm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "0be02456-33db-41eb-98a6-e64e89efd65e",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index: 0, Test set is: train_fold_1.csv\n",
      "FileObject(id='file-piEWevVjKlOkbTIRmBHs6KQu', bytes=101067, created_at=1703616459, filename='test_fold.csv', object='file', purpose='assistants', status='processed', status_details=None)\n",
      "FileObject(id='file-R1OAnWvSEHclDGCD85EkLNLQ', bytes=301754, created_at=1703616461, filename='train_folds.csv', object='file', purpose='assistants', status='processed', status_details=None)\n",
      "Creating Logistic_Regression assistant\n",
      "Creating Random_Forest assistant\n",
      "Index: 1, Test set is: train_fold_2.csv\n",
      "FileObject(id='file-kfIFrkX0ytqrS0FslbjetglO', bytes=101027, created_at=1703616485, filename='test_fold.csv', object='file', purpose='assistants', status='processed', status_details=None)\n",
      "FileObject(id='file-h3oiqXZrtbRlyuXn8NvjOpol', bytes=301794, created_at=1703616488, filename='train_folds.csv', object='file', purpose='assistants', status='processed', status_details=None)\n",
      "Creating Logistic_Regression assistant\n",
      "Creating Random_Forest assistant\n",
      "Index: 2, Test set is: train_fold_3.csv\n",
      "FileObject(id='file-a1V8mT4uX99Q6OgoAEzIcfAK', bytes=100809, created_at=1703616512, filename='test_fold.csv', object='file', purpose='assistants', status='processed', status_details=None)\n",
      "FileObject(id='file-dYHx75jXCsP1T8DL9jLlnR8q', bytes=302012, created_at=1703616514, filename='train_folds.csv', object='file', purpose='assistants', status='processed', status_details=None)\n",
      "Creating Logistic_Regression assistant\n",
      "Creating Random_Forest assistant\n",
      "Index: 3, Test set is: train_fold_4.csv\n",
      "FileObject(id='file-SClHi4bF47MOFwyHdUCdy7TE', bytes=100864, created_at=1703616538, filename='test_fold.csv', object='file', purpose='assistants', status='processed', status_details=None)\n",
      "FileObject(id='file-sTTsPvExyPJO6QsSdTg0iR21', bytes=301957, created_at=1703616540, filename='train_folds.csv', object='file', purpose='assistants', status='processed', status_details=None)\n",
      "Creating Logistic_Regression assistant\n",
      "Creating Random_Forest assistant\n"
     ]
    }
   ],
   "source": [
    "# define model types and file names for iteration\n",
    "# some models to choose from ['Logistic_Regression','Random_Forest','Extra_Trees_Forest','XGBoost', 'Support_Vector_Classifier']\n",
    "model_types = ['Logistic_Regression','Random_Forest']\n",
    "train_files = ['train_fold_1.csv', 'train_fold_2.csv', 'train_fold_3.csv', 'train_fold_4.csv']\n",
    "\n",
    "# empty list to store agent info \n",
    "agents = []\n",
    "# start a loop for each training data fold combination\n",
    "for i, test in enumerate(train_files):\n",
    "    print(f\"Index: {i}, Test set is: {test}\")\n",
    "    test_df, train_df = get_train_test_sets(train_files, i)\n",
    "    test_df.to_csv('test_fold.csv', index=False)\n",
    "    train_df.to_csv('train_folds.csv', index=False)\n",
    "    train_fold_1_id = upload_csv('test_fold.csv')\n",
    "    train_fold_2_id = upload_csv('train_folds.csv')\n",
    "    file_ids = [train_fold_1_id, train_fold_2_id]\n",
    "    for i in model_types:\n",
    "        print(f'Creating {i} assistant')\n",
    "        #assign loop version of models and file names\n",
    "        model = i\n",
    "        instructions = f'''\n",
    "        You are a data scientist who will build a predictive model with data from the provided training and testing csv files. \n",
    "        When the user asks you to perform your ACTIONS, carry out the described ACTIONS on the provided files.\n",
    "        Then continue with each of the steps listed below in your ACTIONS. The target variable is 'diagnosis'. \n",
    "\n",
    "        ACTIONS:\n",
    "\n",
    "        1. Train a {model} model with the file called train_folds.csv\n",
    "        2. Use the trained model to get the probability scores on the testing data file called test_fold.csv\n",
    "        3. Create a table with one column for the row_id, one for the actual taget values in the testing data called 'test_target' and one for the predicted target probability values called 'predicted_target_prob'  \n",
    "        4. Prepare the table as a csv file for the user to download. \n",
    "\n",
    "        DO NOT:\n",
    "        1. Use the column 'row_id' as a feature in the dataset. \n",
    "        2. Return any images. '''    \n",
    "\n",
    "        assistant, thread, run = spin_up(\"class\", instructions, file_ids) \n",
    "        agents.append((assistant, thread, run, model, test))  \n",
    "        time.sleep(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed679a37-2a36-465c-9775-ed3b98142a55",
   "metadata": {},
   "source": [
    "# Catch the Assistant Responses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "041c88a0-dac3-4347-96a5-fc6682d79a0d",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Checking for response...\n",
      "Assistant: The results have been saved to a CSV file. You can download the CSV with predicted probabilities using the link below:\n",
      "\n",
      "[Download predicted_results.csv](sandbox:/mnt/data/predicted_results.csv)\n",
      "Checking for response...\n",
      "Assistant: The predictions have been saved to a CSV file. You can download the file using the link provided below:\n",
      "\n",
      "[Download breast_cancer_predictions.csv](sandbox:/mnt/data/breast_cancer_predictions.csv)\n",
      "Checking for response...\n",
      "Assistant: The results have been saved to a CSV file. You can download the file containing the predictions using the link below:\n",
      "\n",
      "[predicted_probabilities.csv](sandbox:/mnt/data/predicted_probabilities.csv)\n",
      "Checking for response...\n",
      "Assistant: The table with the `row_id`, `test_target`, and `predicted_target_prob` has been saved as a CSV file. You can download it using the link below:\n",
      "\n",
      "[Download predicted_test_results.csv](sandbox:/mnt/data/predicted_test_results.csv)\n",
      "Checking for response...\n",
      "Assistant: The table with the 'row_id', 'test_target', and 'predicted_target_prob' is ready and has been saved as a CSV file.\n",
      "\n",
      "You can download the results file from the following link:\n",
      "\n",
      "[Download predicted_test_results.csv](sandbox:/mnt/data/predicted_test_results.csv)\n",
      "Checking for response...\n",
      "Assistant: The table with `row_id`, the actual target values `test_target`, and the predicted target probability values `predicted_target_prob` has been created and saved as a CSV file. You can download it from the link below:\n",
      "\n",
      "[Download predicted_probabilities.csv](sandbox:/mnt/data/predicted_probabilities.csv)\n",
      "Checking for response...\n",
      "Assistant: The table with the `row_id`, actual target values from the testing data (`test_target`), and the predicted target probability values (`predicted_target_prob`) has been created and prepared as a CSV file. You can download the CSV file from the following link:\n",
      "\n",
      "[Download predicted_test_results.csv](sandbox:/mnt/data/predicted_test_results.csv)\n",
      "Checking for response...\n",
      "Assistant: You can download the CSV file containing the predicted target probabilities from the testing data using the following link:\n",
      "\n",
      "[Download predicted_target_probabilities.csv](sandbox:/mnt/data/predicted_target_probabilities.csv)\n"
     ]
    }
   ],
   "source": [
    "# run a loop to catch the Agent responses\n",
    "time.sleep(240) \n",
    "agent_responses = []\n",
    "for assistant, thread, run, model, test in agents:\n",
    "    messages, content = catch_response(assistant, thread, run) \n",
    "    agent_responses.append((messages, content, model, test))\n",
    "    time.sleep(10) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "deb2108f-6b94-4431-aa45-3d19cb751f4f",
   "metadata": {},
   "source": [
    "# Compile Inference Output and Prepare as Meta Model Input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "ccd974fb-f515-4143-86f9-46179b76b22e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#extract dataframes and compile for accuracy\n",
    "df_list = []\n",
    "for messages, content, model, test in agent_responses:\n",
    "    dataframes = create_dataframes_from_messages(messages, client)\n",
    "    df_list.append([dataframes, model, test])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "1ea524b1-0190-48ff-ab1e-77add9e536f2",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[[        row_id  test_target  predicted_target_prob\n",
       "   0       842302            1               1.000000\n",
       "   1       842517            1               1.000000\n",
       "   2     84300903            1               1.000000\n",
       "   3     84348301            1               0.139500\n",
       "   4     84358402            1               0.999973\n",
       "   ...        ...          ...                    ...\n",
       "   1360    926424            1               1.000000\n",
       "   1361    926682            1               1.000000\n",
       "   1362    926954            1               0.994852\n",
       "   1363    927241            1               1.000000\n",
       "   1364     92751            0               0.011123\n",
       "   \n",
       "   [1365 rows x 3 columns]],\n",
       "  'Logistic_Regression',\n",
       "  'train_fold_1.csv'],\n",
       " [[        row_id  test_target  predicted_target_prob\n",
       "   0       842302            1                   0.90\n",
       "   1       842517            1                   0.98\n",
       "   2     84300903            1                   1.00\n",
       "   3     84348301            1                   0.82\n",
       "   4     84358402            1                   0.83\n",
       "   ...        ...          ...                    ...\n",
       "   1360    926424            1                   1.00\n",
       "   1361    926682            1                   1.00\n",
       "   1362    926954            1                   0.99\n",
       "   1363    927241            1                   1.00\n",
       "   1364     92751            0                   0.00\n",
       "   \n",
       "   [1365 rows x 3 columns]],\n",
       "  'Random_Forest',\n",
       "  'train_fold_1.csv'],\n",
       " [[      row_id  test_target  predicted_target_prob\n",
       "   0     864496            0               0.000066\n",
       "   1     864685            0               0.014586\n",
       "   2     864726            0               0.000021\n",
       "   3     864729            1               0.999604\n",
       "   4     864877            1               0.999985\n",
       "   ...      ...          ...                    ...\n",
       "   1360  926424            1               1.000000\n",
       "   1361  926682            1               1.000000\n",
       "   1362  926954            1               0.997303\n",
       "   1363  927241            1               1.000000\n",
       "   1364   92751            0               0.000412\n",
       "   \n",
       "   [1365 rows x 3 columns]],\n",
       "  'Logistic_Regression',\n",
       "  'train_fold_2.csv'],\n",
       " [[      row_id  test_target  predicted_target_prob\n",
       "   0     864496            0                   0.01\n",
       "   1     864685            0                   0.01\n",
       "   2     864726            0                   0.02\n",
       "   3     864729            1                   0.98\n",
       "   4     864877            1                   1.00\n",
       "   ...      ...          ...                    ...\n",
       "   1360  926424            1                   1.00\n",
       "   1361  926682            1                   1.00\n",
       "   1362  926954            1                   1.00\n",
       "   1363  927241            1                   1.00\n",
       "   1364   92751            0                   0.00\n",
       "   \n",
       "   [1365 rows x 3 columns]],\n",
       "  'Random_Forest',\n",
       "  'train_fold_2.csv'],\n",
       " [[      row_id  test_target  predicted_target_prob\n",
       "   0     864496            0           8.879016e-07\n",
       "   1     864685            0           7.928793e-03\n",
       "   2     864726            0           9.782068e-08\n",
       "   3     864729            1           9.998721e-01\n",
       "   4     864877            1           9.999969e-01\n",
       "   ...      ...          ...                    ...\n",
       "   1360  926424            1           1.000000e+00\n",
       "   1361  926682            1           9.999999e-01\n",
       "   1362  926954            1           9.986084e-01\n",
       "   1363  927241            1           1.000000e+00\n",
       "   1364   92751            0           1.858102e-06\n",
       "   \n",
       "   [1365 rows x 3 columns]],\n",
       "  'Logistic_Regression',\n",
       "  'train_fold_3.csv'],\n",
       " [[      row_id  test_target  predicted_target_prob\n",
       "   0     864496            0                   0.00\n",
       "   1     864685            0                   0.01\n",
       "   2     864726            0                   0.03\n",
       "   3     864729            1                   0.98\n",
       "   4     864877            1                   1.00\n",
       "   ...      ...          ...                    ...\n",
       "   1360  926424            1                   1.00\n",
       "   1361  926682            1                   1.00\n",
       "   1362  926954            1                   0.99\n",
       "   1363  927241            1                   1.00\n",
       "   1364   92751            0                   0.01\n",
       "   \n",
       "   [1365 rows x 3 columns]],\n",
       "  'Random_Forest',\n",
       "  'train_fold_3.csv'],\n",
       " [[      row_id  test_target  predicted_target_prob\n",
       "   0     864496            0               0.000424\n",
       "   1     864685            0               0.039888\n",
       "   2     864726            0               0.000269\n",
       "   3     864729            1               0.999499\n",
       "   4     864877            1               0.999992\n",
       "   ...      ...          ...                    ...\n",
       "   1360  926424            1               1.000000\n",
       "   1361  926682            1               1.000000\n",
       "   1362  926954            1               0.997469\n",
       "   1363  927241            1               1.000000\n",
       "   1364   92751            0               0.004860\n",
       "   \n",
       "   [1365 rows x 3 columns]],\n",
       "  'Logistic_Regression',\n",
       "  'train_fold_4.csv'],\n",
       " [[      row_id  test_target  predicted_target_prob\n",
       "   0     864496            0                   0.00\n",
       "   1     864685            0                   0.00\n",
       "   2     864726            0                   0.00\n",
       "   3     864729            1                   0.97\n",
       "   4     864877            1                   1.00\n",
       "   ...      ...          ...                    ...\n",
       "   1360  926424            1                   0.99\n",
       "   1361  926682            1                   1.00\n",
       "   1362  926954            1                   0.99\n",
       "   1363  927241            1                   1.00\n",
       "   1364   92751            0                   0.02\n",
       "   \n",
       "   [1365 rows x 3 columns]],\n",
       "  'Random_Forest',\n",
       "  'train_fold_4.csv']]"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "9914f268-5869-40e5-96be-bfc547d55ed1",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>row_id</th>\n",
       "      <th>test_target</th>\n",
       "      <th>Log1.csv</th>\n",
       "      <th>Ran1.csv</th>\n",
       "      <th>Log2.csv</th>\n",
       "      <th>Ran2.csv</th>\n",
       "      <th>Log3.csv</th>\n",
       "      <th>Ran3.csv</th>\n",
       "      <th>Log4.csv</th>\n",
       "      <th>Ran4.csv</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>842302</td>\n",
       "      <td>1</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.90</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.96</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.89</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.90</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>842517</td>\n",
       "      <td>1</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.98</td>\n",
       "      <td>0.999999</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.999969</td>\n",
       "      <td>0.97</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.99</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>84300903</td>\n",
       "      <td>1</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>84348301</td>\n",
       "      <td>1</td>\n",
       "      <td>0.139500</td>\n",
       "      <td>0.82</td>\n",
       "      <td>0.558984</td>\n",
       "      <td>0.81</td>\n",
       "      <td>0.670836</td>\n",
       "      <td>0.87</td>\n",
       "      <td>0.564326</td>\n",
       "      <td>0.89</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>84358402</td>\n",
       "      <td>1</td>\n",
       "      <td>0.999973</td>\n",
       "      <td>0.83</td>\n",
       "      <td>0.999957</td>\n",
       "      <td>0.95</td>\n",
       "      <td>0.999643</td>\n",
       "      <td>0.94</td>\n",
       "      <td>0.999852</td>\n",
       "      <td>0.96</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>638</th>\n",
       "      <td>8812877</td>\n",
       "      <td>1</td>\n",
       "      <td>0.976780</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.994341</td>\n",
       "      <td>0.97</td>\n",
       "      <td>0.998421</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.992173</td>\n",
       "      <td>1.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>639</th>\n",
       "      <td>8813129</td>\n",
       "      <td>0</td>\n",
       "      <td>0.038639</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.042199</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.021333</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.057604</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>640</th>\n",
       "      <td>88143502</td>\n",
       "      <td>0</td>\n",
       "      <td>0.282207</td>\n",
       "      <td>0.11</td>\n",
       "      <td>0.410951</td>\n",
       "      <td>0.29</td>\n",
       "      <td>0.215220</td>\n",
       "      <td>0.07</td>\n",
       "      <td>0.412197</td>\n",
       "      <td>0.09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>641</th>\n",
       "      <td>88147101</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000452</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.000076</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.000008</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.000370</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>642</th>\n",
       "      <td>88147102</td>\n",
       "      <td>0</td>\n",
       "      <td>0.023462</td>\n",
       "      <td>0.07</td>\n",
       "      <td>0.048260</td>\n",
       "      <td>0.19</td>\n",
       "      <td>0.030745</td>\n",
       "      <td>0.03</td>\n",
       "      <td>0.042203</td>\n",
       "      <td>0.07</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>643 rows × 10 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       row_id  test_target  Log1.csv  Ran1.csv  Log2.csv  Ran2.csv  Log3.csv  \\\n",
       "0      842302            1  1.000000      0.90  1.000000      0.96  1.000000   \n",
       "1      842517            1  1.000000      0.98  0.999999      1.00  0.999969   \n",
       "2    84300903            1  1.000000      1.00  1.000000      1.00  1.000000   \n",
       "3    84348301            1  0.139500      0.82  0.558984      0.81  0.670836   \n",
       "4    84358402            1  0.999973      0.83  0.999957      0.95  0.999643   \n",
       "..        ...          ...       ...       ...       ...       ...       ...   \n",
       "638   8812877            1  0.976780      1.00  0.994341      0.97  0.998421   \n",
       "639   8813129            0  0.038639      0.01  0.042199      0.00  0.021333   \n",
       "640  88143502            0  0.282207      0.11  0.410951      0.29  0.215220   \n",
       "641  88147101            0  0.000452      0.00  0.000076      0.00  0.000008   \n",
       "642  88147102            0  0.023462      0.07  0.048260      0.19  0.030745   \n",
       "\n",
       "     Ran3.csv  Log4.csv  Ran4.csv  \n",
       "0        0.89  1.000000      0.90  \n",
       "1        0.97  1.000000      0.99  \n",
       "2        1.00  1.000000      1.00  \n",
       "3        0.87  0.564326      0.89  \n",
       "4        0.94  0.999852      0.96  \n",
       "..        ...       ...       ...  \n",
       "638      1.00  0.992173      1.00  \n",
       "639      0.00  0.057604      0.00  \n",
       "640      0.07  0.412197      0.09  \n",
       "641      0.00  0.000370      0.00  \n",
       "642      0.03  0.042203      0.07  \n",
       "\n",
       "[643 rows x 10 columns]"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "consolidated_df = consolidate_response_dfs(df_list)\n",
    "consolidated_df = consolidated_df.reset_index(drop=True)\n",
    "consolidated_df.to_csv('consolidated_df.csv', index=False)\n",
    "consolidated_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "ad04f854-1f38-4b48-952f-8624a01c5ddb",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>row_id</th>\n",
       "      <th>test_target</th>\n",
       "      <th>Log1.csv</th>\n",
       "      <th>Ran1.csv</th>\n",
       "      <th>Log2.csv</th>\n",
       "      <th>Ran2.csv</th>\n",
       "      <th>Log3.csv</th>\n",
       "      <th>Ran3.csv</th>\n",
       "      <th>Log4.csv</th>\n",
       "      <th>Ran4.csv</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>842302</td>\n",
       "      <td>1</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.90</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.96</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.89</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.90</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>842517</td>\n",
       "      <td>1</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.98</td>\n",
       "      <td>0.999999</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.999969</td>\n",
       "      <td>0.97</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.99</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>84300903</td>\n",
       "      <td>1</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>84348301</td>\n",
       "      <td>1</td>\n",
       "      <td>0.139500</td>\n",
       "      <td>0.82</td>\n",
       "      <td>0.558984</td>\n",
       "      <td>0.81</td>\n",
       "      <td>0.670836</td>\n",
       "      <td>0.87</td>\n",
       "      <td>0.564326</td>\n",
       "      <td>0.89</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>84358402</td>\n",
       "      <td>1</td>\n",
       "      <td>0.999973</td>\n",
       "      <td>0.83</td>\n",
       "      <td>0.999957</td>\n",
       "      <td>0.95</td>\n",
       "      <td>0.999643</td>\n",
       "      <td>0.94</td>\n",
       "      <td>0.999852</td>\n",
       "      <td>0.96</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>638</th>\n",
       "      <td>8812877</td>\n",
       "      <td>1</td>\n",
       "      <td>0.976780</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.994341</td>\n",
       "      <td>0.97</td>\n",
       "      <td>0.998421</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.992173</td>\n",
       "      <td>1.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>639</th>\n",
       "      <td>8813129</td>\n",
       "      <td>0</td>\n",
       "      <td>0.038639</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.042199</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.021333</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.057604</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>640</th>\n",
       "      <td>88143502</td>\n",
       "      <td>0</td>\n",
       "      <td>0.282207</td>\n",
       "      <td>0.11</td>\n",
       "      <td>0.410951</td>\n",
       "      <td>0.29</td>\n",
       "      <td>0.215220</td>\n",
       "      <td>0.07</td>\n",
       "      <td>0.412197</td>\n",
       "      <td>0.09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>641</th>\n",
       "      <td>88147101</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000452</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.000076</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.000008</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.000370</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>642</th>\n",
       "      <td>88147102</td>\n",
       "      <td>0</td>\n",
       "      <td>0.023462</td>\n",
       "      <td>0.07</td>\n",
       "      <td>0.048260</td>\n",
       "      <td>0.19</td>\n",
       "      <td>0.030745</td>\n",
       "      <td>0.03</td>\n",
       "      <td>0.042203</td>\n",
       "      <td>0.07</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>643 rows × 10 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       row_id  test_target  Log1.csv  Ran1.csv  Log2.csv  Ran2.csv  Log3.csv  \\\n",
       "0      842302            1  1.000000      0.90  1.000000      0.96  1.000000   \n",
       "1      842517            1  1.000000      0.98  0.999999      1.00  0.999969   \n",
       "2    84300903            1  1.000000      1.00  1.000000      1.00  1.000000   \n",
       "3    84348301            1  0.139500      0.82  0.558984      0.81  0.670836   \n",
       "4    84358402            1  0.999973      0.83  0.999957      0.95  0.999643   \n",
       "..        ...          ...       ...       ...       ...       ...       ...   \n",
       "638   8812877            1  0.976780      1.00  0.994341      0.97  0.998421   \n",
       "639   8813129            0  0.038639      0.01  0.042199      0.00  0.021333   \n",
       "640  88143502            0  0.282207      0.11  0.410951      0.29  0.215220   \n",
       "641  88147101            0  0.000452      0.00  0.000076      0.00  0.000008   \n",
       "642  88147102            0  0.023462      0.07  0.048260      0.19  0.030745   \n",
       "\n",
       "     Ran3.csv  Log4.csv  Ran4.csv  \n",
       "0        0.89  1.000000      0.90  \n",
       "1        0.97  1.000000      0.99  \n",
       "2        1.00  1.000000      1.00  \n",
       "3        0.87  0.564326      0.89  \n",
       "4        0.94  0.999852      0.96  \n",
       "..        ...       ...       ...  \n",
       "638      1.00  0.992173      1.00  \n",
       "639      0.00  0.057604      0.00  \n",
       "640      0.07  0.412197      0.09  \n",
       "641      0.00  0.000370      0.00  \n",
       "642      0.03  0.042203      0.07  \n",
       "\n",
       "[643 rows x 10 columns]"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# or you can start here\n",
    "consolidated_df = pd.read_csv('consolidated_df.csv')\n",
    "consolidated_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4689ee6-9789-4477-af88-783a82298d3e",
   "metadata": {},
   "source": [
    "# Train Meta Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "67c7371e-f1b9-47d9-8601-a5a78acdbfe6",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {color: black;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>ExtraTreesClassifier(n_estimators=3000, random_state=42)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">ExtraTreesClassifier</label><div class=\"sk-toggleable__content\"><pre>ExtraTreesClassifier(n_estimators=3000, random_state=42)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "ExtraTreesClassifier(n_estimators=3000, random_state=42)"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Train a extxra trees forest with all of the consolidated data\n",
    "\n",
    "from sklearn.ensemble import ExtraTreesClassifier\n",
    "\n",
    "# Assuming consolidated_df and validation_df are already defined and preprocessed\n",
    "X_train = consolidated_df.drop(['row_id', 'test_target'], axis=1) \n",
    "y_train = consolidated_df['test_target']\n",
    "\n",
    "# Create the Extra Trees Classifier with 3000 trees\n",
    "extra_trees_model = ExtraTreesClassifier(n_estimators=3000, random_state=42)\n",
    "\n",
    "# Fit the model to the training data\n",
    "extra_trees_model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0fe16347-4043-4c8e-989a-cbf4e575a51f",
   "metadata": {},
   "source": [
    "# Have Assistants Score Validation Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "2d29b58c-fdf2-4ef4-b88b-df5bf994c30d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def give_new_file(assistant, file_name):\n",
    "    # give assistant a new file\n",
    "    train_fold_id = upload_csv(file_name)\n",
    "    file_ids = [train_fold_id]\n",
    "    updated_assistant = client.beta.assistants.update(\n",
    "      assistant.id,\n",
    "      file_ids=file_ids,)\n",
    "    return updated_assistant, file_ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "56f5073c-9ab7-4b3a-81e0-52f8db928919",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FileObject(id='file-9eLuBfDHBEkRC0eo0PeqqCvB', bytes=100864, created_at=1703616897, filename='test_fold.csv', object='file', purpose='assistants', status='processed', status_details=None)\n",
      "FileObject(id='file-PE1S2BfOkc5Kc1TQil5wyvqi', bytes=100864, created_at=1703616910, filename='test_fold.csv', object='file', purpose='assistants', status='processed', status_details=None)\n",
      "FileObject(id='file-kx97lja0TCu7P5bBWMsx7Aaz', bytes=100864, created_at=1703616922, filename='test_fold.csv', object='file', purpose='assistants', status='processed', status_details=None)\n",
      "FileObject(id='file-alsy94DmZmZqhEh4EEwfKNqS', bytes=100864, created_at=1703616934, filename='test_fold.csv', object='file', purpose='assistants', status='processed', status_details=None)\n",
      "FileObject(id='file-vZhVZMKzQ7TPhTplXeBAijMo', bytes=100864, created_at=1703616946, filename='test_fold.csv', object='file', purpose='assistants', status='processed', status_details=None)\n",
      "FileObject(id='file-YqY02zoGb4Cm5V8FtXO187yS', bytes=100864, created_at=1703616958, filename='test_fold.csv', object='file', purpose='assistants', status='processed', status_details=None)\n",
      "FileObject(id='file-K9RngnfKPtxJZt3ccYXS6VwD', bytes=100864, created_at=1703616970, filename='test_fold.csv', object='file', purpose='assistants', status='processed', status_details=None)\n",
      "FileObject(id='file-YZNDfzOru0msq9w73LgyiTWc', bytes=100864, created_at=1703616983, filename='test_fold.csv', object='file', purpose='assistants', status='processed', status_details=None)\n"
     ]
    }
   ],
   "source": [
    "# send the final validation data to the agents for scoring\n",
    "new_file_name = 'test_fold.csv'\n",
    "\n",
    "updated_assistant_list = []\n",
    "for assistant, thread, run, model, test in agents:\n",
    "    updated_assistant, file_ids = give_new_file(assistant, new_file_name)\n",
    "    updated_assistant_list.append(([updated_assistant, file_ids, thread, model, test]))\n",
    "    time.sleep(10) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "0c11bfa1-6fae-49eb-89ca-6e74bddab296",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def follow_up_message(updated_assistant, thread, follow_up_text):\n",
    "    # Create a message to append to our thread\n",
    "    message = client.beta.threads.messages.create(thread_id=thread.id, role=\"user\", content=follow_up_text)\n",
    "    run = client.beta.threads.runs.create(thread_id=thread.id, assistant_id=updated_assistant.id,)\n",
    "    return run, thread"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "e9d7e2e7-fc9d-40c6-a403-6c34a3bb7c41",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "messaging to asst_aHezfWMBzWYEuVYfBWKCwPmf\n",
      "messaging to asst_fHmGyog2S6DEKtrutl1UZUHH\n",
      "messaging to asst_jHSpR4a9X1UyVTKNnGW90z6g\n",
      "messaging to asst_a4d5010HvnSNYRB4S6P31di2\n",
      "messaging to asst_PhPRI5EgRjq9wTpmSNvTUuuM\n",
      "messaging to asst_y036NeSKpuZfmrikCATCV74K\n",
      "messaging to asst_VfMpxK2x8gVE5a1t9z7n4SI7\n",
      "messaging to asst_BXl014L0gA8UEJoYOlsWTftW\n"
     ]
    }
   ],
   "source": [
    "#send the follow up message\n",
    "\n",
    "time.sleep(120) \n",
    "follow_up_messages = []\n",
    "for updated_assistant, file_ids, thread, model, test in updated_assistant_list:\n",
    "    follow_up_text = f'Please use the trained model to provide probability scores on the validation data in the file {file_ids} and prepare the scores for download as a df with only the columns row_id and predicted_target_prob.'\n",
    "    print(f'messaging to {updated_assistant.id}')\n",
    "    new_run, new_thread = follow_up_message(updated_assistant, thread, follow_up_text)\n",
    "    follow_up_messages.append(([updated_assistant, new_run, new_thread, model]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "ee59258b-d5d9-4f50-85fc-e68086634454",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "reading message by asst_aHezfWMBzWYEuVYfBWKCwPmf\n",
      "Checking for response...\n",
      "Assistant: The predicted probabilities for the validation data have now been calculated correctly and are saved in a CSV file. You can download this CSV file containing the `row_id` and `predicted_target_prob` columns using the following link:\n",
      "\n",
      "[Download predicted_validation_results_final.csv](sandbox:/mnt/data/predicted_validation_results_final.csv)\n",
      "reading message by asst_fHmGyog2S6DEKtrutl1UZUHH\n",
      "Checking for response...\n",
      "Assistant: The probability scores for the validation data have been calculated using the trained Random Forest model and saved to a CSV file. The CSV file contains only the `row_id` and the `predicted_target_prob` columns as requested.\n",
      "\n",
      "You can download the file using the link provided below:\n",
      "\n",
      "[Download breast_cancer_validation_corrected_predictions.csv](sandbox:/mnt/data/breast_cancer_validation_corrected_predictions.csv)\n",
      "reading message by asst_jHSpR4a9X1UyVTKNnGW90z6g\n",
      "Checking for response...\n",
      "Assistant: The probability scores for the validation data have been successfully computed and saved to a CSV file. You can download the file using the link below:\n",
      "\n",
      "[validation_predicted_probabilities.csv](sandbox:/mnt/data/validation_predicted_probabilities.csv)\n",
      "reading message by asst_a4d5010HvnSNYRB4S6P31di2\n",
      "Checking for response...\n",
      "Assistant: The probability scores for the validation data have been predicted and saved as a CSV file containing the `row_id` and `predicted_target_prob` columns. You can download it using the link below:\n",
      "\n",
      "[Download validation_predicted_probs.csv](sandbox:/mnt/data/validation_predicted_probs.csv)\n",
      "reading message by asst_PhPRI5EgRjq9wTpmSNvTUuuM\n",
      "Checking for response...\n",
      "Assistant: The probability scores for the validation set have been successfully computed, and the results have been saved to a CSV file with only the 'row_id' and 'predicted_target_prob' columns.\n",
      "\n",
      "You can download the validation results file from the following link:\n",
      "\n",
      "[Download validation_predicted_probs.csv](sandbox:/mnt/data/validation_predicted_probs.csv)\n",
      "reading message by asst_y036NeSKpuZfmrikCATCV74K\n",
      "Checking for response...\n",
      "Assistant: The probability scores for the `diagnosis` in the validation data have been predicted using the trained Random Forest model, and the results have been saved as a CSV file. You can download the file with only the `row_id` and `predicted_target_prob` columns from the following link:\n",
      "\n",
      "[Download validation_predicted_probabilities.csv](sandbox:/mnt/data/validation_predicted_probabilities.csv)\n",
      "reading message by asst_VfMpxK2x8gVE5a1t9z7n4SI7\n",
      "Checking for response...\n",
      "Assistant: The probability scores have been generated for the validation data using the trained Logistic Regression model. A CSV file with the `row_id` and `predicted_target_prob` columns has been prepared for download. You can download the file from the following link:\n",
      "\n",
      "[Download predicted_validation_results.csv](sandbox:/mnt/data/predicted_validation_results.csv)\n",
      "reading message by asst_BXl014L0gA8UEJoYOlsWTftW\n",
      "Checking for response...\n",
      "Assistant: You can download the CSV file containing the predicted target probabilities for the validation data using the following link:\n",
      "\n",
      "[Download validation_predicted_probabilities.csv](sandbox:/mnt/data/validation_predicted_probabilities.csv)\n"
     ]
    }
   ],
   "source": [
    "# catch follow up responses\n",
    "\n",
    "time.sleep(120) \n",
    "updated_agent_responses = []\n",
    "for updated_assistant, new_run, new_thread, model in follow_up_messages:\n",
    "    test = 'inf'\n",
    "    print(f'reading message by {updated_assistant.id}')\n",
    "    messages, content = catch_response(updated_assistant, new_thread, new_run) \n",
    "    updated_agent_responses.append((messages, content, model, test))\n",
    "    time.sleep(10) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "ae5c4c8e-b959-425c-8222-55360856b598",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# retrieve the scored validation set\n",
    "val_df_list = []\n",
    "for messages, content, model, test in updated_agent_responses:\n",
    "    dataframes = create_dataframes_from_messages(messages, client)\n",
    "    val_df_list.append([dataframes, model, test])\n",
    "    time.sleep(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "f5f5f680-e963-4a88-b56b-18813fbd8d56",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[[       row_id  predicted_target_prob\n",
       "   0      842302               1.000000\n",
       "   1      842517               1.000000\n",
       "   2    84300903               1.000000\n",
       "   3    84348301               0.139500\n",
       "   4    84358402               0.999973\n",
       "   ..        ...                    ...\n",
       "   450    926424               1.000000\n",
       "   451    926682               1.000000\n",
       "   452    926954               0.994852\n",
       "   453    927241               1.000000\n",
       "   454     92751               0.011123\n",
       "   \n",
       "   [455 rows x 2 columns]],\n",
       "  'Logistic_Regression',\n",
       "  'inf'],\n",
       " [[       row_id  predicted_target_prob\n",
       "   0      842302                   0.90\n",
       "   1      842517                   0.98\n",
       "   2    84300903                   1.00\n",
       "   3    84348301                   0.82\n",
       "   4    84358402                   0.83\n",
       "   ..        ...                    ...\n",
       "   450    926424                   1.00\n",
       "   451    926682                   1.00\n",
       "   452    926954                   0.99\n",
       "   453    927241                   1.00\n",
       "   454     92751                   0.00\n",
       "   \n",
       "   [455 rows x 2 columns]],\n",
       "  'Random_Forest',\n",
       "  'inf'],\n",
       " [[       row_id  predicted_target_prob\n",
       "   0      842302               1.000000\n",
       "   1      842517               0.999999\n",
       "   2    84300903               1.000000\n",
       "   3    84348301               0.558984\n",
       "   4    84358402               0.999957\n",
       "   ..        ...                    ...\n",
       "   450    926424               1.000000\n",
       "   451    926682               1.000000\n",
       "   452    926954               0.997303\n",
       "   453    927241               1.000000\n",
       "   454     92751               0.000412\n",
       "   \n",
       "   [455 rows x 2 columns]],\n",
       "  'Logistic_Regression',\n",
       "  'inf'],\n",
       " [[       row_id  predicted_target_prob\n",
       "   0      842302                   0.96\n",
       "   1      842517                   1.00\n",
       "   2    84300903                   1.00\n",
       "   3    84348301                   0.81\n",
       "   4    84358402                   0.95\n",
       "   ..        ...                    ...\n",
       "   450    926424                   1.00\n",
       "   451    926682                   1.00\n",
       "   452    926954                   1.00\n",
       "   453    927241                   1.00\n",
       "   454     92751                   0.00\n",
       "   \n",
       "   [455 rows x 2 columns]],\n",
       "  'Random_Forest',\n",
       "  'inf'],\n",
       " [[       row_id  predicted_target_prob\n",
       "   0      842302               1.000000\n",
       "   1      842517               0.999969\n",
       "   2    84300903               1.000000\n",
       "   3    84348301               0.670836\n",
       "   4    84358402               0.999643\n",
       "   ..        ...                    ...\n",
       "   450    926424               1.000000\n",
       "   451    926682               1.000000\n",
       "   452    926954               0.998608\n",
       "   453    927241               1.000000\n",
       "   454     92751               0.000002\n",
       "   \n",
       "   [455 rows x 2 columns]],\n",
       "  'Logistic_Regression',\n",
       "  'inf'],\n",
       " [[       row_id  predicted_target_prob\n",
       "   0      842302                   0.89\n",
       "   1      842517                   0.97\n",
       "   2    84300903                   1.00\n",
       "   3    84348301                   0.87\n",
       "   4    84358402                   0.94\n",
       "   ..        ...                    ...\n",
       "   450    926424                   1.00\n",
       "   451    926682                   1.00\n",
       "   452    926954                   0.99\n",
       "   453    927241                   1.00\n",
       "   454     92751                   0.01\n",
       "   \n",
       "   [455 rows x 2 columns]],\n",
       "  'Random_Forest',\n",
       "  'inf'],\n",
       " [[       row_id  predicted_target_prob\n",
       "   0      842302               1.000000\n",
       "   1      842517               1.000000\n",
       "   2    84300903               1.000000\n",
       "   3    84348301               0.564326\n",
       "   4    84358402               0.999852\n",
       "   ..        ...                    ...\n",
       "   450    926424               1.000000\n",
       "   451    926682               1.000000\n",
       "   452    926954               0.997469\n",
       "   453    927241               1.000000\n",
       "   454     92751               0.004860\n",
       "   \n",
       "   [455 rows x 2 columns]],\n",
       "  'Logistic_Regression',\n",
       "  'inf'],\n",
       " [[       row_id  predicted_target_prob\n",
       "   0      842302                   0.90\n",
       "   1      842517                   0.99\n",
       "   2    84300903                   1.00\n",
       "   3    84348301                   0.89\n",
       "   4    84358402                   0.96\n",
       "   ..        ...                    ...\n",
       "   450    926424                   0.99\n",
       "   451    926682                   1.00\n",
       "   452    926954                   0.99\n",
       "   453    927241                   1.00\n",
       "   454     92751                   0.02\n",
       "   \n",
       "   [455 rows x 2 columns]],\n",
       "  'Random_Forest',\n",
       "  'inf']]"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val_df_list "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1dfd248e-2319-4402-a00a-b83a16d2636a",
   "metadata": {},
   "source": [
    "# Consolidate Responses and Score with Meta Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "192ee7db-eb17-4da6-b132-8b2cde6d4153",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def consolidate_follow_up_dfs(df_list):\n",
    "    x = 0\n",
    "    # create empty DataFrame for the predicted_mpg values\n",
    "    predicted_df = pd.DataFrame()\n",
    "    # Loop through each DataFrame in the list\n",
    "    for i, df_tuple in enumerate(df_list):\n",
    "        # Check if the tuple is not empty\n",
    "        if df_tuple:\n",
    "            df = df_tuple[0][0]\n",
    "            # Check if 'predicted_target_prob' column exists in df\n",
    "            if 'predicted_target_prob' in df.columns:\n",
    "                # Rename 'predicted_mpg' column to match which agent predicted it \n",
    "                model = df_list[i][1]\n",
    "                train = df_list[i][2]\n",
    "                column_name = model[:3] + train[-5:] + str(x)\n",
    "                x = x+1\n",
    "                df = df.rename(columns={'predicted_target_prob': column_name})\n",
    "                # Select only the 'row_id' and the renamed 'predicted_mpg' column\n",
    "                #df = df[['row_id', f'predicted_target_prob{i+1}']]\n",
    "                df = df[['row_id', column_name]]\n",
    "                # initialize predicted_mpg_df on the first iteration\n",
    "                if i == 0:\n",
    "                    predicted_df = df\n",
    "                else:\n",
    "                    # Join using 'row_id'\n",
    "                    predicted_df = predicted_df.merge(df, on='row_id', how='outer', suffixes=('', '_dup'))\n",
    "            else:\n",
    "                print(f'Column \"predicted_target_prob\" not found in run {i}')\n",
    "        else:\n",
    "            print(f'run {i} is empty')\n",
    "    # Join the 'actual_mpg' with the predicted_mpg_df\n",
    "    #consolidated_df = actual.merge(predicted_df, on='row_id', how='outer')\n",
    "    # Calculate the average of the predictions and add it as a new column\n",
    "    prediction_columns = [col for col in predicted_df.columns if col.startswith('predicted_target_prob')]\n",
    "    prediction_columns = consolidated_df.dropna()\n",
    "    return prediction_columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "a8bd2e39-16a4-4e9b-acbf-b0b8b021d31c",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>row_id</th>\n",
       "      <th>test_target</th>\n",
       "      <th>Log1.csv</th>\n",
       "      <th>Ran1.csv</th>\n",
       "      <th>Log2.csv</th>\n",
       "      <th>Ran2.csv</th>\n",
       "      <th>Log3.csv</th>\n",
       "      <th>Ran3.csv</th>\n",
       "      <th>Log4.csv</th>\n",
       "      <th>Ran4.csv</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>842302</td>\n",
       "      <td>1</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.90</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.96</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.89</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.90</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>842517</td>\n",
       "      <td>1</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.98</td>\n",
       "      <td>0.999999</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.999969</td>\n",
       "      <td>0.97</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.99</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>84300903</td>\n",
       "      <td>1</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>84348301</td>\n",
       "      <td>1</td>\n",
       "      <td>0.139500</td>\n",
       "      <td>0.82</td>\n",
       "      <td>0.558984</td>\n",
       "      <td>0.81</td>\n",
       "      <td>0.670836</td>\n",
       "      <td>0.87</td>\n",
       "      <td>0.564326</td>\n",
       "      <td>0.89</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>84358402</td>\n",
       "      <td>1</td>\n",
       "      <td>0.999973</td>\n",
       "      <td>0.83</td>\n",
       "      <td>0.999957</td>\n",
       "      <td>0.95</td>\n",
       "      <td>0.999643</td>\n",
       "      <td>0.94</td>\n",
       "      <td>0.999852</td>\n",
       "      <td>0.96</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>638</th>\n",
       "      <td>8812877</td>\n",
       "      <td>1</td>\n",
       "      <td>0.976780</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.994341</td>\n",
       "      <td>0.97</td>\n",
       "      <td>0.998421</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.992173</td>\n",
       "      <td>1.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>639</th>\n",
       "      <td>8813129</td>\n",
       "      <td>0</td>\n",
       "      <td>0.038639</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.042199</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.021333</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.057604</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>640</th>\n",
       "      <td>88143502</td>\n",
       "      <td>0</td>\n",
       "      <td>0.282207</td>\n",
       "      <td>0.11</td>\n",
       "      <td>0.410951</td>\n",
       "      <td>0.29</td>\n",
       "      <td>0.215220</td>\n",
       "      <td>0.07</td>\n",
       "      <td>0.412197</td>\n",
       "      <td>0.09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>641</th>\n",
       "      <td>88147101</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000452</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.000076</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.000008</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.000370</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>642</th>\n",
       "      <td>88147102</td>\n",
       "      <td>0</td>\n",
       "      <td>0.023462</td>\n",
       "      <td>0.07</td>\n",
       "      <td>0.048260</td>\n",
       "      <td>0.19</td>\n",
       "      <td>0.030745</td>\n",
       "      <td>0.03</td>\n",
       "      <td>0.042203</td>\n",
       "      <td>0.07</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>643 rows × 10 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       row_id  test_target  Log1.csv  Ran1.csv  Log2.csv  Ran2.csv  Log3.csv  \\\n",
       "0      842302            1  1.000000      0.90  1.000000      0.96  1.000000   \n",
       "1      842517            1  1.000000      0.98  0.999999      1.00  0.999969   \n",
       "2    84300903            1  1.000000      1.00  1.000000      1.00  1.000000   \n",
       "3    84348301            1  0.139500      0.82  0.558984      0.81  0.670836   \n",
       "4    84358402            1  0.999973      0.83  0.999957      0.95  0.999643   \n",
       "..        ...          ...       ...       ...       ...       ...       ...   \n",
       "638   8812877            1  0.976780      1.00  0.994341      0.97  0.998421   \n",
       "639   8813129            0  0.038639      0.01  0.042199      0.00  0.021333   \n",
       "640  88143502            0  0.282207      0.11  0.410951      0.29  0.215220   \n",
       "641  88147101            0  0.000452      0.00  0.000076      0.00  0.000008   \n",
       "642  88147102            0  0.023462      0.07  0.048260      0.19  0.030745   \n",
       "\n",
       "     Ran3.csv  Log4.csv  Ran4.csv  \n",
       "0        0.89  1.000000      0.90  \n",
       "1        0.97  1.000000      0.99  \n",
       "2        1.00  1.000000      1.00  \n",
       "3        0.87  0.564326      0.89  \n",
       "4        0.94  0.999852      0.96  \n",
       "..        ...       ...       ...  \n",
       "638      1.00  0.992173      1.00  \n",
       "639      0.00  0.057604      0.00  \n",
       "640      0.07  0.412197      0.09  \n",
       "641      0.00  0.000370      0.00  \n",
       "642      0.03  0.042203      0.07  \n",
       "\n",
       "[643 rows x 10 columns]"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inferences_df = consolidate_follow_up_dfs(val_df_list)\n",
    "inferences_df = inferences_df.reset_index(drop=True)\n",
    "inferences_df.to_csv('inferences_df.csv', index=False)\n",
    "inferences_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "232f9d74-c4c0-4726-9a3c-36e3380bb780",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>row_id</th>\n",
       "      <th>test_target</th>\n",
       "      <th>Log1.csv</th>\n",
       "      <th>Ran1.csv</th>\n",
       "      <th>Log2.csv</th>\n",
       "      <th>Ran2.csv</th>\n",
       "      <th>Log3.csv</th>\n",
       "      <th>Ran3.csv</th>\n",
       "      <th>Log4.csv</th>\n",
       "      <th>Ran4.csv</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>842302</td>\n",
       "      <td>1</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.90</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.96</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.89</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.90</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>842517</td>\n",
       "      <td>1</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.98</td>\n",
       "      <td>0.999999</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.999969</td>\n",
       "      <td>0.97</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.99</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>84300903</td>\n",
       "      <td>1</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>84348301</td>\n",
       "      <td>1</td>\n",
       "      <td>0.139500</td>\n",
       "      <td>0.82</td>\n",
       "      <td>0.558984</td>\n",
       "      <td>0.81</td>\n",
       "      <td>0.670836</td>\n",
       "      <td>0.87</td>\n",
       "      <td>0.564326</td>\n",
       "      <td>0.89</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>84358402</td>\n",
       "      <td>1</td>\n",
       "      <td>0.999973</td>\n",
       "      <td>0.83</td>\n",
       "      <td>0.999957</td>\n",
       "      <td>0.95</td>\n",
       "      <td>0.999643</td>\n",
       "      <td>0.94</td>\n",
       "      <td>0.999852</td>\n",
       "      <td>0.96</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>638</th>\n",
       "      <td>8812877</td>\n",
       "      <td>1</td>\n",
       "      <td>0.976780</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.994341</td>\n",
       "      <td>0.97</td>\n",
       "      <td>0.998421</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.992173</td>\n",
       "      <td>1.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>639</th>\n",
       "      <td>8813129</td>\n",
       "      <td>0</td>\n",
       "      <td>0.038639</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.042199</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.021333</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.057604</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>640</th>\n",
       "      <td>88143502</td>\n",
       "      <td>0</td>\n",
       "      <td>0.282207</td>\n",
       "      <td>0.11</td>\n",
       "      <td>0.410951</td>\n",
       "      <td>0.29</td>\n",
       "      <td>0.215220</td>\n",
       "      <td>0.07</td>\n",
       "      <td>0.412197</td>\n",
       "      <td>0.09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>641</th>\n",
       "      <td>88147101</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000452</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.000076</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.000008</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.000370</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>642</th>\n",
       "      <td>88147102</td>\n",
       "      <td>0</td>\n",
       "      <td>0.023462</td>\n",
       "      <td>0.07</td>\n",
       "      <td>0.048260</td>\n",
       "      <td>0.19</td>\n",
       "      <td>0.030745</td>\n",
       "      <td>0.03</td>\n",
       "      <td>0.042203</td>\n",
       "      <td>0.07</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>643 rows × 10 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       row_id  test_target  Log1.csv  Ran1.csv  Log2.csv  Ran2.csv  Log3.csv  \\\n",
       "0      842302            1  1.000000      0.90  1.000000      0.96  1.000000   \n",
       "1      842517            1  1.000000      0.98  0.999999      1.00  0.999969   \n",
       "2    84300903            1  1.000000      1.00  1.000000      1.00  1.000000   \n",
       "3    84348301            1  0.139500      0.82  0.558984      0.81  0.670836   \n",
       "4    84358402            1  0.999973      0.83  0.999957      0.95  0.999643   \n",
       "..        ...          ...       ...       ...       ...       ...       ...   \n",
       "638   8812877            1  0.976780      1.00  0.994341      0.97  0.998421   \n",
       "639   8813129            0  0.038639      0.01  0.042199      0.00  0.021333   \n",
       "640  88143502            0  0.282207      0.11  0.410951      0.29  0.215220   \n",
       "641  88147101            0  0.000452      0.00  0.000076      0.00  0.000008   \n",
       "642  88147102            0  0.023462      0.07  0.048260      0.19  0.030745   \n",
       "\n",
       "     Ran3.csv  Log4.csv  Ran4.csv  \n",
       "0        0.89  1.000000      0.90  \n",
       "1        0.97  1.000000      0.99  \n",
       "2        1.00  1.000000      1.00  \n",
       "3        0.87  0.564326      0.89  \n",
       "4        0.94  0.999852      0.96  \n",
       "..        ...       ...       ...  \n",
       "638      1.00  0.992173      1.00  \n",
       "639      0.00  0.057604      0.00  \n",
       "640      0.07  0.412197      0.09  \n",
       "641      0.00  0.000370      0.00  \n",
       "642      0.03  0.042203      0.07  \n",
       "\n",
       "[643 rows x 10 columns]"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# or you can start here\n",
    "inferences_df = pd.read_csv('inferences_df.csv')\n",
    "inferences_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "8017b46e-eec6-443f-a61b-6536497d4dbf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>class_0</th>\n",
       "      <th>class_1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>638</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>639</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>640</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>641</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>642</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>643 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     class_0  class_1\n",
       "0        0.0      1.0\n",
       "1        0.0      1.0\n",
       "2        0.0      1.0\n",
       "3        0.0      1.0\n",
       "4        0.0      1.0\n",
       "..       ...      ...\n",
       "638      0.0      1.0\n",
       "639      1.0      0.0\n",
       "640      1.0      0.0\n",
       "641      1.0      0.0\n",
       "642      1.0      0.0\n",
       "\n",
       "[643 rows x 2 columns]"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# test meta model with the validation fold (train_fold_5)\n",
    "X_val = inferences_df.drop(['row_id', 'test_target'], axis=1) \n",
    "y_val = inferences_df['test_target']\n",
    "\n",
    "# Predict probabilities on the validation dataset\n",
    "probabilities = extra_trees_model.predict_proba(X_val)\n",
    "\n",
    "prob_df = pd.DataFrame(probabilities, columns=extra_trees_model.classes_)\n",
    "prob_df.columns = ['class_' + str(col) for col in prob_df.columns]\n",
    "prob_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "427b97e6-2ce6-4f7f-8a12-4766de2cd997",
   "metadata": {},
   "source": [
    "# Analyze Performance of Stacking Models and Meta Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "3a00b9b7-1144-41cc-bdc7-b272d5b32e4e",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>key</th>\n",
       "      <th>class_0</th>\n",
       "      <th>class_1</th>\n",
       "      <th>row_id</th>\n",
       "      <th>test_target</th>\n",
       "      <th>Log1.csv</th>\n",
       "      <th>Ran1.csv</th>\n",
       "      <th>Log2.csv</th>\n",
       "      <th>Ran2.csv</th>\n",
       "      <th>Log3.csv</th>\n",
       "      <th>Ran3.csv</th>\n",
       "      <th>Log4.csv</th>\n",
       "      <th>Ran4.csv</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>842302</td>\n",
       "      <td>1</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.90</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.96</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.89</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.90</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>842517</td>\n",
       "      <td>1</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.98</td>\n",
       "      <td>0.999999</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.999969</td>\n",
       "      <td>0.97</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.99</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>84300903</td>\n",
       "      <td>1</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>84348301</td>\n",
       "      <td>1</td>\n",
       "      <td>0.139500</td>\n",
       "      <td>0.82</td>\n",
       "      <td>0.558984</td>\n",
       "      <td>0.81</td>\n",
       "      <td>0.670836</td>\n",
       "      <td>0.87</td>\n",
       "      <td>0.564326</td>\n",
       "      <td>0.89</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>84358402</td>\n",
       "      <td>1</td>\n",
       "      <td>0.999973</td>\n",
       "      <td>0.83</td>\n",
       "      <td>0.999957</td>\n",
       "      <td>0.95</td>\n",
       "      <td>0.999643</td>\n",
       "      <td>0.94</td>\n",
       "      <td>0.999852</td>\n",
       "      <td>0.96</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>638</th>\n",
       "      <td>638</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>8812877</td>\n",
       "      <td>1</td>\n",
       "      <td>0.976780</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.994341</td>\n",
       "      <td>0.97</td>\n",
       "      <td>0.998421</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.992173</td>\n",
       "      <td>1.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>639</th>\n",
       "      <td>639</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>8813129</td>\n",
       "      <td>0</td>\n",
       "      <td>0.038639</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.042199</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.021333</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.057604</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>640</th>\n",
       "      <td>640</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>88143502</td>\n",
       "      <td>0</td>\n",
       "      <td>0.282207</td>\n",
       "      <td>0.11</td>\n",
       "      <td>0.410951</td>\n",
       "      <td>0.29</td>\n",
       "      <td>0.215220</td>\n",
       "      <td>0.07</td>\n",
       "      <td>0.412197</td>\n",
       "      <td>0.09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>641</th>\n",
       "      <td>641</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>88147101</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000452</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.000076</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.000008</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.000370</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>642</th>\n",
       "      <td>642</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>88147102</td>\n",
       "      <td>0</td>\n",
       "      <td>0.023462</td>\n",
       "      <td>0.07</td>\n",
       "      <td>0.048260</td>\n",
       "      <td>0.19</td>\n",
       "      <td>0.030745</td>\n",
       "      <td>0.03</td>\n",
       "      <td>0.042203</td>\n",
       "      <td>0.07</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>643 rows × 13 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     key  class_0  class_1    row_id  test_target  Log1.csv  Ran1.csv  \\\n",
       "0      0      0.0      1.0    842302            1  1.000000      0.90   \n",
       "1      1      0.0      1.0    842517            1  1.000000      0.98   \n",
       "2      2      0.0      1.0  84300903            1  1.000000      1.00   \n",
       "3      3      0.0      1.0  84348301            1  0.139500      0.82   \n",
       "4      4      0.0      1.0  84358402            1  0.999973      0.83   \n",
       "..   ...      ...      ...       ...          ...       ...       ...   \n",
       "638  638      0.0      1.0   8812877            1  0.976780      1.00   \n",
       "639  639      1.0      0.0   8813129            0  0.038639      0.01   \n",
       "640  640      1.0      0.0  88143502            0  0.282207      0.11   \n",
       "641  641      1.0      0.0  88147101            0  0.000452      0.00   \n",
       "642  642      1.0      0.0  88147102            0  0.023462      0.07   \n",
       "\n",
       "     Log2.csv  Ran2.csv  Log3.csv  Ran3.csv  Log4.csv  Ran4.csv  \n",
       "0    1.000000      0.96  1.000000      0.89  1.000000      0.90  \n",
       "1    0.999999      1.00  0.999969      0.97  1.000000      0.99  \n",
       "2    1.000000      1.00  1.000000      1.00  1.000000      1.00  \n",
       "3    0.558984      0.81  0.670836      0.87  0.564326      0.89  \n",
       "4    0.999957      0.95  0.999643      0.94  0.999852      0.96  \n",
       "..        ...       ...       ...       ...       ...       ...  \n",
       "638  0.994341      0.97  0.998421      1.00  0.992173      1.00  \n",
       "639  0.042199      0.00  0.021333      0.00  0.057604      0.00  \n",
       "640  0.410951      0.29  0.215220      0.07  0.412197      0.09  \n",
       "641  0.000076      0.00  0.000008      0.00  0.000370      0.00  \n",
       "642  0.048260      0.19  0.030745      0.03  0.042203      0.07  \n",
       "\n",
       "[643 rows x 13 columns]"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prob_df_final = prob_df.reset_index(inplace=False)\n",
    "prob_df_final = prob_df_final.rename(columns={'index': 'key'}, inplace=False)\n",
    "\n",
    "inf_df_final = inferences_df.reset_index(inplace=False)\n",
    "inf_df_final = inf_df_final.rename(columns={'index': 'key'}, inplace=False)\n",
    "\n",
    "final_val_scores = prob_df_final.merge(inf_df_final, on='key', how='outer', suffixes=('', '_dup'))\n",
    "final_val_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "9cac0166-b94e-4c4b-8f1c-ab059c5392b0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0, 0, 430, 213, 1.0, 1.0, 1.0]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score, recall_score, precision_score\n",
    "\n",
    "# Example usage\n",
    "metrics = calculate_performance_metrics(final_val_scores, 'test_target', 'class_1')\n",
    "print(metrics)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "afc0fab3-0fcc-442d-8f8f-ed64aa5a127a",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[[1.0, 1.0, 1.0], 'meta_model'],\n",
       " [[0.9642301710730948, 0.9154929577464789, 0.975], 'Log1.csv'],\n",
       " [[0.9844479004665629, 0.9577464788732394, 0.9951219512195122], 'Ran1.csv'],\n",
       " [[0.9626749611197511, 0.9295774647887324, 0.9565217391304348], 'Log2.csv'],\n",
       " [[0.9922239502332815, 0.9859154929577465, 0.9905660377358491], 'Ran2.csv'],\n",
       " [[0.968895800933126, 0.9389671361502347, 0.966183574879227], 'Log3.csv'],\n",
       " [[0.9922239502332815, 0.9765258215962441, 1.0], 'Ran3.csv'],\n",
       " [[0.9626749611197511, 0.9389671361502347, 0.9478672985781991], 'Log4.csv'],\n",
       " [[0.9906687402799378, 0.9812206572769953, 0.990521327014218], 'Ran4.csv']]"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "score_cols = final_val_scores.drop(['key', 'class_0', 'class_1', 'row_id'], axis = 1)\n",
    "col_names = score_cols.columns\n",
    "\n",
    "results = []\n",
    "for col in col_names:\n",
    "    metrics = calculate_performance_metrics(score_cols, 'test_target', col)\n",
    "    row = [metrics[-3:], col]\n",
    "    results.append(row) \n",
    "    \n",
    "results[0][1] = 'meta_model'    \n",
    "results       "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bcc79970-bd93-4d44-9475-bbcb9d414645",
   "metadata": {},
   "source": [
    " # Visualize the Model Performances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "979b78f3-2011-4aa3-91cb-bf628b21d20a",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1200x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "# Extracting model names, accuracies, precisions, and recalls\n",
    "model_names = [model[1] for model in results]\n",
    "accuracies = [model[0][0] for model in results]\n",
    "precisions = [model[0][1] for model in results]\n",
    "recalls = [model[0][2] for model in results]\n",
    "\n",
    "# Setting up the bar chart\n",
    "x = np.arange(len(model_names))  # the label locations\n",
    "width = 0.2  # the width of the bars\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(12, 6))\n",
    "rects1 = ax.bar(x - width, accuracies, width, label='Accuracy')\n",
    "rects2 = ax.bar(x, precisions, width, label='Precision')\n",
    "rects3 = ax.bar(x + width, recalls, width, label='Recall')\n",
    "\n",
    "# Add some text for labels, title and custom x-axis tick labels, etc.\n",
    "ax.set_xlabel('Models')\n",
    "ax.set_ylabel('Scores')\n",
    "ax.set_title('Model Performance Comparison')\n",
    "ax.set_xticks(x)\n",
    "ax.set_xticklabels(model_names)\n",
    "ax.legend()\n",
    "\n",
    "ax.set_ylim(0.80, 1.1)\n",
    "\n",
    "# Function to attach a label above each bar\n",
    "def autolabel(rects):\n",
    "    for rect in rects:\n",
    "        height = rect.get_height()\n",
    "        ax.annotate(f'{height:.2f}',\n",
    "                    xy=(rect.get_x() + rect.get_width() / 2, height),\n",
    "                    xytext=(0, 3),  # 3 points vertical offset\n",
    "                    textcoords=\"offset points\",\n",
    "                    ha='center', va='bottom')\n",
    "\n",
    "autolabel(rects1)\n",
    "autolabel(rects2)\n",
    "autolabel(rects3)\n",
    "fig.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2194780-ff04-4758-936c-1448f351863a",
   "metadata": {},
   "source": [
    "## Clean Up Agents and Files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "d34d331f-37ea-4365-b8d3-55c3cd4d6ff1",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#delete_all_agents() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "c9adedba-68cc-4293-9e97-b67464ce0c8a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#delete_all_assistant_files()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
